{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenDroneDatasetSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgvinholi/DroneDatasetSegmentation/blob/main/OpenDroneDatasetSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy3kU3HnOqfq"
      },
      "source": [
        "# Colab Specs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1_8h-oaQCPB"
      },
      "source": [
        "from psutil import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIpEOQTYQQz8"
      },
      "source": [
        "virtual_memory()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DIwWpkbOxtt"
      },
      "source": [
        "!df -h #disk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGGa2DwKO2on"
      },
      "source": [
        "!cat /proc/meminfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnXrmYTKffHo"
      },
      "source": [
        "#Save or Retrieve Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVeEWQ2PeKEK"
      },
      "source": [
        "# Set user\n",
        "user = 0   #Vinholi\n",
        "# user = 1   #Debora\n",
        "# user = 2 # Conta Compartilhada\n",
        "\n",
        "# Save image to drive\n",
        "save_img = False\n",
        "\n",
        "# Define GDrive paths\n",
        "if user==0:\n",
        "  base_dir = '/content/drive/MyDrive/ITA/ML/projeto_drone_ita/'\n",
        "elif user==1:   \n",
        "  base_dir = '/content/drive/MyDrive/mestrado/PO-233/projeto_drone_ita/'\n",
        "elif user==2:\n",
        "  base_dir = '/content/drive/MyDrive/'\n",
        "\n",
        "working_dir = '/content/SemanticDroneDataset/'\n",
        "dataset_dir = base_dir+'SemanticDroneDataset/' \n",
        "backup_dir = base_dir+'SemanticDroneDataset_backup/'\n",
        "analise_dir = working_dir+'analise/' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeoa8erlgMWs",
        "outputId": "31aa7154-11d4-4506-de81-bf50e9ef26f5"
      },
      "source": [
        "# Mount GDrive folder:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMN4a0j9gSi4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "770aa8a4-0433-4f8b-ae68-6554167fd322"
      },
      "source": [
        "# Get files from Gdrive:\n",
        "!rsync -avh {dataset_dir} '/content/SemanticDroneDataset' "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sending incremental file list\n",
            "created directory /content/SemanticDroneDataset\n",
            "./\n",
            ".ipynb_checkpoints/\n",
            "analise/\n",
            "analise/confusion_matrix_testset.eps\n",
            "analise/confusion_matrix_trainset.eps\n",
            "analise/fig_table_attributes_actv_0.eps\n",
            "analise/fig_table_attributes_actv_16.eps\n",
            "analise/fig_table_attributes_actv_3.eps\n",
            "analise/fig_table_attributes_actv_last.eps\n",
            "analise/overall_metrics_table.csv\n",
            "analise/overall_metrics_test.pkl\n",
            "analise/overall_metrics_train.pkl\n",
            "analise/overall_metrics_val.pkl\n",
            "analise/pairgrid_table_attributes_actv_last.eps\n",
            "analise/.ipynb_checkpoints/\n",
            "analise/detections/\n",
            "analise/detections/446_gt.png\n",
            "analise/detections/446_pred.png\n",
            "analise/detections/447_gt.png\n",
            "analise/detections/447_pred.png\n",
            "analise/detections/451_gt.png\n",
            "analise/detections/451_pred.png\n",
            "analise/detections/452_gt.png\n",
            "analise/detections/452_pred.png\n",
            "analise/detections/454_gt.png\n",
            "analise/detections/454_pred.png\n",
            "analise/detections/455_gt.png\n",
            "analise/detections/455_pred.png\n",
            "analise/detections/457_gt.png\n",
            "analise/detections/457_pred.png\n",
            "analise/detections/458_gt.png\n",
            "analise/detections/458_pred.png\n",
            "analise/detections/460_gt.png\n",
            "analise/detections/460_pred.png\n",
            "analise/detections/461_gt.png\n",
            "analise/detections/461_pred.png\n",
            "analise/detections/462_gt.png\n",
            "analise/detections/462_pred.png\n",
            "analise/detections/463_gt.png\n",
            "analise/detections/463_pred.png\n",
            "analise/detections/464_gt.png\n",
            "analise/detections/464_pred.png\n",
            "analise/detections/465_gt.png\n",
            "analise/detections/465_pred.png\n",
            "analise/detections/467_gt.png\n",
            "analise/detections/467_pred.png\n",
            "analise/detections/470_gt.png\n",
            "analise/detections/470_pred.png\n",
            "analise/detections/472_gt.png\n",
            "analise/detections/472_pred.png\n",
            "analise/detections/473_gt.png\n",
            "analise/detections/473_pred.png\n",
            "analise/detections/474_gt.png\n",
            "analise/detections/474_pred.png\n",
            "analise/detections/475_gt.png\n",
            "analise/detections/475_pred.png\n",
            "analise/detections/476_gt.png\n",
            "analise/detections/476_pred.png\n",
            "analise/detections/478_gt.png\n",
            "analise/detections/478_pred.png\n",
            "analise/detections/479_gt.png\n",
            "analise/detections/479_pred.png\n",
            "analise/detections/480_gt.png\n",
            "analise/detections/480_pred.png\n",
            "analise/detections/484_gt.png\n",
            "analise/detections/484_pred.png\n",
            "analise/detections/485_gt.png\n",
            "analise/detections/485_pred.png\n",
            "analise/detections/488_gt.png\n",
            "analise/detections/488_pred.png\n",
            "analise/detections/489_gt.png\n",
            "analise/detections/489_pred.png\n",
            "analise/detections/491_gt.png\n",
            "analise/detections/491_pred.png\n",
            "analise/detections/493_gt.png\n",
            "analise/detections/493_pred.png\n",
            "analise/detections/494_gt.png\n",
            "analise/detections/494_pred.png\n",
            "analise/detections/497_gt.png\n",
            "analise/detections/497_pred.png\n",
            "analise/detections/498_gt.png\n",
            "analise/detections/498_pred.png\n",
            "analise/detections/499_gt.png\n",
            "analise/detections/499_pred.png\n",
            "analise/detections/500_gt.png\n",
            "analise/detections/500_pred.png\n",
            "analise/detections/501_gt.png\n",
            "analise/detections/501_pred.png\n",
            "analise/detections/502_gt.png\n",
            "analise/detections/502_pred.png\n",
            "analise/detections/507_gt.png\n",
            "analise/detections/507_pred.png\n",
            "analise/detections/508_gt.png\n",
            "analise/detections/508_pred.png\n",
            "analise/detections/509_gt.png\n",
            "analise/detections/509_pred.png\n",
            "analise/detections/510_gt.png\n",
            "analise/detections/510_pred.png\n",
            "analise/detections/512_gt.png\n",
            "analise/detections/512_pred.png\n",
            "analise/detections/513_gt.png\n",
            "analise/detections/513_pred.png\n",
            "analise/detections/514_gt.png\n",
            "analise/detections/514_pred.png\n",
            "analise/detections/515_gt.png\n",
            "analise/detections/515_pred.png\n",
            "analise/detections/517_gt.png\n",
            "analise/detections/517_pred.png\n",
            "analise/detections/518_gt.png\n",
            "analise/detections/518_pred.png\n",
            "analise/detections/521_gt.png\n",
            "analise/detections/521_pred.png\n",
            "analise/detections/524_gt.png\n",
            "analise/detections/524_pred.png\n",
            "analise/detections/525_gt.png\n",
            "analise/detections/525_pred.png\n",
            "analise/detections/526_gt.png\n",
            "analise/detections/526_pred.png\n",
            "analise/detections/529_gt.png\n",
            "analise/detections/529_pred.png\n",
            "analise/detections/530_gt.png\n",
            "analise/detections/530_pred.png\n",
            "analise/detections/531_gt.png\n",
            "analise/detections/531_pred.png\n",
            "analise/detections/532_gt.png\n",
            "analise/detections/532_pred.png\n",
            "analise/detections/533_gt.png\n",
            "analise/detections/533_pred.png\n",
            "analise/detections/535_gt.png\n",
            "analise/detections/535_pred.png\n",
            "analise/detections/536_gt.png\n",
            "analise/detections/536_pred.png\n",
            "analise/detections/537_gt.png\n",
            "analise/detections/537_pred.png\n",
            "analise/detections/538_gt.png\n",
            "analise/detections/538_pred.png\n",
            "analise/detections/540_gt.png\n",
            "analise/detections/540_pred.png\n",
            "analise/detections/543_gt.png\n",
            "analise/detections/543_pred.png\n",
            "analise/detections/544_gt.png\n",
            "analise/detections/544_pred.png\n",
            "analise/detections/545_gt.png\n",
            "analise/detections/545_pred.png\n",
            "analise/detections/549_gt.png\n",
            "analise/detections/549_pred.png\n",
            "analise/detections/551_gt.png\n",
            "analise/detections/551_pred.png\n",
            "analise/detections/554_gt.png\n",
            "analise/detections/554_pred.png\n",
            "analise/detections/556_gt.png\n",
            "analise/detections/556_pred.png\n",
            "analise/detections/558_gt.png\n",
            "analise/detections/558_pred.png\n",
            "analise/detections/559_gt.png\n",
            "analise/detections/559_pred.png\n",
            "analise/detections/560_gt.png\n",
            "analise/detections/560_pred.png\n",
            "analise/detections/561_gt.png\n",
            "analise/detections/561_pred.png\n",
            "analise/detections/563_gt.png\n",
            "analise/detections/563_pred.png\n",
            "analise/detections/564_gt.png\n",
            "analise/detections/564_pred.png\n",
            "analise/detections/565_gt.png\n",
            "analise/detections/565_pred.png\n",
            "analise/detections/566_gt.png\n",
            "analise/detections/566_pred.png\n",
            "analise/detections/567_gt.png\n",
            "analise/detections/567_pred.png\n",
            "analise/detections/568_gt.png\n",
            "analise/detections/568_pred.png\n",
            "analise/detections/569_gt.png\n",
            "analise/detections/569_pred.png\n",
            "analise/detections/570_gt.png\n",
            "analise/detections/570_pred.png\n",
            "analise/detections/572_gt.png\n",
            "analise/detections/572_pred.png\n",
            "analise/detections/573_gt.png\n",
            "analise/detections/573_pred.png\n",
            "analise/detections/574_gt.png\n",
            "analise/detections/574_pred.png\n",
            "analise/detections/576_gt.png\n",
            "analise/detections/576_pred.png\n",
            "analise/detections/579_gt.png\n",
            "analise/detections/579_pred.png\n",
            "analise/detections/580_gt.png\n",
            "analise/detections/580_pred.png\n",
            "analise/detections/582_gt.png\n",
            "analise/detections/582_pred.png\n",
            "analise/detections/583_gt.png\n",
            "analise/detections/583_pred.png\n",
            "analise/detections/584_gt.png\n",
            "analise/detections/584_pred.png\n",
            "analise/detections/585_gt.png\n",
            "analise/detections/585_pred.png\n",
            "analise/detections/586_gt.png\n",
            "analise/detections/586_pred.png\n",
            "analise/detections/587_gt.png\n",
            "analise/detections/587_pred.png\n",
            "analise/detections/588_gt.png\n",
            "analise/detections/588_pred.png\n",
            "analise/detections/590_gt.png\n",
            "analise/detections/590_pred.png\n",
            "analise/detections/591_gt.png\n",
            "analise/detections/591_pred.png\n",
            "analise/detections/592_gt.png\n",
            "analise/detections/592_pred.png\n",
            "analise/detections/593_gt.png\n",
            "analise/detections/593_pred.png\n",
            "analise/detections/594_gt.png\n",
            "analise/detections/594_pred.png\n",
            "analise/detections/596_gt.png\n",
            "analise/detections/596_pred.png\n",
            "analise/detections/598_gt.png\n",
            "analise/detections/598_pred.png\n",
            "code/\n",
            "code/basefunctions.py\n",
            "code/.ipynb_checkpoints/\n",
            "code/__pycache__/\n",
            "code/__pycache__/basefunctions.cpython-37.pyc\n",
            "code/segmentation_models/\n",
            "code/segmentation_models/.gitignore\n",
            "code/segmentation_models/.gitmodules\n",
            "code/segmentation_models/.travis.yml\n",
            "code/segmentation_models/CHANGELOG.md\n",
            "code/segmentation_models/LICENSE\n",
            "code/segmentation_models/MANIFEST.in\n",
            "code/segmentation_models/README.rst\n",
            "code/segmentation_models/__init__.py\n",
            "code/segmentation_models/requirements.txt\n",
            "code/segmentation_models/setup.py\n",
            "code/segmentation_models/.git/\n",
            "code/segmentation_models/.git/HEAD\n",
            "code/segmentation_models/.git/config\n",
            "code/segmentation_models/.git/description\n",
            "code/segmentation_models/.git/index\n",
            "code/segmentation_models/.git/packed-refs\n",
            "code/segmentation_models/.git/hooks/\n",
            "code/segmentation_models/.git/hooks/applypatch-msg.sample\n",
            "code/segmentation_models/.git/hooks/commit-msg.sample\n",
            "code/segmentation_models/.git/hooks/fsmonitor-watchman.sample\n",
            "code/segmentation_models/.git/hooks/post-update.sample\n",
            "code/segmentation_models/.git/hooks/pre-applypatch.sample\n",
            "code/segmentation_models/.git/hooks/pre-commit.sample\n",
            "code/segmentation_models/.git/hooks/pre-merge-commit.sample\n",
            "code/segmentation_models/.git/hooks/pre-push.sample\n",
            "code/segmentation_models/.git/hooks/pre-rebase.sample\n",
            "code/segmentation_models/.git/hooks/pre-receive.sample\n",
            "code/segmentation_models/.git/hooks/prepare-commit-msg.sample\n",
            "code/segmentation_models/.git/hooks/push-to-checkout.sample\n",
            "code/segmentation_models/.git/hooks/update.sample\n",
            "code/segmentation_models/.git/info/\n",
            "code/segmentation_models/.git/info/exclude\n",
            "code/segmentation_models/.git/logs/\n",
            "code/segmentation_models/.git/logs/HEAD\n",
            "code/segmentation_models/.git/logs/refs/\n",
            "code/segmentation_models/.git/logs/refs/heads/\n",
            "code/segmentation_models/.git/logs/refs/heads/master\n",
            "code/segmentation_models/.git/logs/refs/remotes/\n",
            "code/segmentation_models/.git/logs/refs/remotes/origin/\n",
            "code/segmentation_models/.git/logs/refs/remotes/origin/HEAD\n",
            "code/segmentation_models/.git/objects/\n",
            "code/segmentation_models/.git/objects/info/\n",
            "code/segmentation_models/.git/objects/pack/\n",
            "code/segmentation_models/.git/objects/pack/pack-054eb6e17da8d80e14ca6f8542f23553acbce2ac.idx\n",
            "code/segmentation_models/.git/objects/pack/pack-054eb6e17da8d80e14ca6f8542f23553acbce2ac.pack\n",
            "code/segmentation_models/.git/refs/\n",
            "code/segmentation_models/.git/refs/heads/\n",
            "code/segmentation_models/.git/refs/heads/master\n",
            "code/segmentation_models/.git/refs/remotes/\n",
            "code/segmentation_models/.git/refs/remotes/origin/\n",
            "code/segmentation_models/.git/refs/remotes/origin/HEAD\n",
            "code/segmentation_models/.git/refs/tags/\n",
            "code/segmentation_models/.github/\n",
            "code/segmentation_models/.github/FUNDING.yml\n",
            "code/segmentation_models/docs/\n",
            "code/segmentation_models/docs/Makefile\n",
            "code/segmentation_models/docs/api.rst\n",
            "code/segmentation_models/docs/conf.py\n",
            "code/segmentation_models/docs/index.rst\n",
            "code/segmentation_models/docs/install.rst\n",
            "code/segmentation_models/docs/support.rst\n",
            "code/segmentation_models/docs/tutorial.rst\n",
            "code/segmentation_models/examples/\n",
            "code/segmentation_models/examples/binary segmentation (camvid).ipynb\n",
            "code/segmentation_models/examples/multiclass segmentation (camvid).ipynb\n",
            "code/segmentation_models/images/\n",
            "code/segmentation_models/images/fpn.png\n",
            "code/segmentation_models/images/linknet.png\n",
            "code/segmentation_models/images/logo.png\n",
            "code/segmentation_models/images/pspnet.png\n",
            "code/segmentation_models/images/unet.png\n",
            "code/segmentation_models/segmentation_models/\n",
            "code/segmentation_models/segmentation_models/__init__.py\n",
            "code/segmentation_models/segmentation_models/__version__.py\n",
            "code/segmentation_models/segmentation_models/losses.py\n",
            "code/segmentation_models/segmentation_models/metrics.py\n",
            "code/segmentation_models/segmentation_models/utils.py\n",
            "code/segmentation_models/segmentation_models/backbones/\n",
            "code/segmentation_models/segmentation_models/backbones/__init__.py\n",
            "code/segmentation_models/segmentation_models/backbones/backbones_factory.py\n",
            "code/segmentation_models/segmentation_models/backbones/inception_resnet_v2.py\n",
            "code/segmentation_models/segmentation_models/backbones/inception_v3.py\n",
            "code/segmentation_models/segmentation_models/base/\n",
            "code/segmentation_models/segmentation_models/base/__init__.py\n",
            "code/segmentation_models/segmentation_models/base/functional.py\n",
            "code/segmentation_models/segmentation_models/base/objects.py\n",
            "code/segmentation_models/segmentation_models/models/\n",
            "code/segmentation_models/segmentation_models/models/__init__.py\n",
            "code/segmentation_models/segmentation_models/models/_common_blocks.py\n",
            "code/segmentation_models/segmentation_models/models/_utils.py\n",
            "code/segmentation_models/segmentation_models/models/fpn.py\n",
            "code/segmentation_models/segmentation_models/models/linknet.py\n",
            "code/segmentation_models/segmentation_models/models/pspnet.py\n",
            "code/segmentation_models/segmentation_models/models/unet.py\n",
            "code/segmentation_models/tests/\n",
            "code/segmentation_models/tests/test_metrics.py\n",
            "code/segmentation_models/tests/test_models.py\n",
            "code/segmentation_models/tests/test_utils.py\n",
            "gt/\n",
            "gt/class_dict.csv\n",
            "gt/class_dict_norm.csv\n",
            "gt/label_images/\n",
            "gt/label_images/000.png\n",
            "gt/label_images/001.png\n",
            "gt/label_images/002.png\n",
            "gt/label_images/003.png\n",
            "gt/label_images/004.png\n",
            "gt/label_images/005.png\n",
            "gt/label_images/006.png\n",
            "gt/label_images/008.png\n",
            "gt/label_images/011.png\n",
            "gt/label_images/013.png\n",
            "gt/label_images/014.png\n",
            "gt/label_images/015.png\n",
            "gt/label_images/016.png\n",
            "gt/label_images/018.png\n",
            "gt/label_images/019.png\n",
            "gt/label_images/021.png\n",
            "gt/label_images/022.png\n",
            "gt/label_images/023.png\n",
            "gt/label_images/026.png\n",
            "gt/label_images/028.png\n",
            "gt/label_images/031.png\n",
            "gt/label_images/035.png\n",
            "gt/label_images/038.png\n",
            "gt/label_images/040.png\n",
            "gt/label_images/041.png\n",
            "gt/label_images/042.png\n",
            "gt/label_images/043.png\n",
            "gt/label_images/044.png\n",
            "gt/label_images/045.png\n",
            "gt/label_images/047.png\n",
            "gt/label_images/049.png\n",
            "gt/label_images/051.png\n",
            "gt/label_images/052.png\n",
            "gt/label_images/053.png\n",
            "gt/label_images/055.png\n",
            "gt/label_images/056.png\n",
            "gt/label_images/057.png\n",
            "gt/label_images/058.png\n",
            "gt/label_images/059.png\n",
            "gt/label_images/060.png\n",
            "gt/label_images/062.png\n",
            "gt/label_images/063.png\n",
            "gt/label_images/065.png\n",
            "gt/label_images/068.png\n",
            "gt/label_images/070.png\n",
            "gt/label_images/071.png\n",
            "gt/label_images/073.png\n",
            "gt/label_images/074.png\n",
            "gt/label_images/075.png\n",
            "gt/label_images/077.png\n",
            "gt/label_images/078.png\n",
            "gt/label_images/079.png\n",
            "gt/label_images/080.png\n",
            "gt/label_images/081.png\n",
            "gt/label_images/083.png\n",
            "gt/label_images/086.png\n",
            "gt/label_images/088.png\n",
            "gt/label_images/089.png\n",
            "gt/label_images/092.png\n",
            "gt/label_images/095.png\n",
            "gt/label_images/098.png\n",
            "gt/label_images/099.png\n",
            "gt/label_images/100.png\n",
            "gt/label_images/101.png\n",
            "gt/label_images/102.png\n",
            "gt/label_images/103.png\n",
            "gt/label_images/104.png\n",
            "gt/label_images/106.png\n",
            "gt/label_images/107.png\n",
            "gt/label_images/109.png\n",
            "gt/label_images/110.png\n",
            "gt/label_images/111.png\n",
            "gt/label_images/112.png\n",
            "gt/label_images/113.png\n",
            "gt/label_images/116.png\n",
            "gt/label_images/117.png\n",
            "gt/label_images/118.png\n",
            "gt/label_images/119.png\n",
            "gt/label_images/120.png\n",
            "gt/label_images/121.png\n",
            "gt/label_images/122.png\n",
            "gt/label_images/123.png\n",
            "gt/label_images/124.png\n",
            "gt/label_images/126.png\n",
            "gt/label_images/128.png\n",
            "gt/label_images/130.png\n",
            "gt/label_images/133.png\n",
            "gt/label_images/134.png\n",
            "gt/label_images/135.png\n",
            "gt/label_images/136.png\n",
            "gt/label_images/137.png\n",
            "gt/label_images/138.png\n",
            "gt/label_images/139.png\n",
            "gt/label_images/140.png\n",
            "gt/label_images/141.png\n",
            "gt/label_images/145.png\n",
            "gt/label_images/146.png\n",
            "gt/label_images/147.png\n",
            "gt/label_images/148.png\n",
            "gt/label_images/149.png\n",
            "gt/label_images/150.png\n",
            "gt/label_images/153.png\n",
            "gt/label_images/154.png\n",
            "gt/label_images/155.png\n",
            "gt/label_images/156.png\n",
            "gt/label_images/157.png\n",
            "gt/label_images/158.png\n",
            "gt/label_images/159.png\n",
            "gt/label_images/160.png\n",
            "gt/label_images/161.png\n",
            "gt/label_images/162.png\n",
            "gt/label_images/163.png\n",
            "gt/label_images/164.png\n",
            "gt/label_images/165.png\n",
            "gt/label_images/166.png\n",
            "gt/label_images/167.png\n",
            "gt/label_images/170.png\n",
            "gt/label_images/171.png\n",
            "gt/label_images/172.png\n",
            "gt/label_images/173.png\n",
            "gt/label_images/174.png\n",
            "gt/label_images/175.png\n",
            "gt/label_images/176.png\n",
            "gt/label_images/177.png\n",
            "gt/label_images/178.png\n",
            "gt/label_images/179.png\n",
            "gt/label_images/180.png\n",
            "gt/label_images/181.png\n",
            "gt/label_images/182.png\n",
            "gt/label_images/185.png\n",
            "gt/label_images/186.png\n",
            "gt/label_images/188.png\n",
            "gt/label_images/190.png\n",
            "gt/label_images/192.png\n",
            "gt/label_images/193.png\n",
            "gt/label_images/194.png\n",
            "gt/label_images/195.png\n",
            "gt/label_images/198.png\n",
            "gt/label_images/199.png\n",
            "gt/label_images/200.png\n",
            "gt/label_images/202.png\n",
            "gt/label_images/204.png\n",
            "gt/label_images/206.png\n",
            "gt/label_images/207.png\n",
            "gt/label_images/208.png\n",
            "gt/label_images/209.png\n",
            "gt/label_images/213.png\n",
            "gt/label_images/214.png\n",
            "gt/label_images/215.png\n",
            "gt/label_images/216.png\n",
            "gt/label_images/217.png\n",
            "gt/label_images/219.png\n",
            "gt/label_images/220.png\n",
            "gt/label_images/221.png\n",
            "gt/label_images/222.png\n",
            "gt/label_images/223.png\n",
            "gt/label_images/225.png\n",
            "gt/label_images/226.png\n",
            "gt/label_images/228.png\n",
            "gt/label_images/229.png\n",
            "gt/label_images/230.png\n",
            "gt/label_images/232.png\n",
            "gt/label_images/233.png\n",
            "gt/label_images/234.png\n",
            "gt/label_images/235.png\n",
            "gt/label_images/236.png\n",
            "gt/label_images/237.png\n",
            "gt/label_images/238.png\n",
            "gt/label_images/239.png\n",
            "gt/label_images/240.png\n",
            "gt/label_images/243.png\n",
            "gt/label_images/244.png\n",
            "gt/label_images/246.png\n",
            "gt/label_images/248.png\n",
            "gt/label_images/250.png\n",
            "gt/label_images/251.png\n",
            "gt/label_images/252.png\n",
            "gt/label_images/255.png\n",
            "gt/label_images/257.png\n",
            "gt/label_images/258.png\n",
            "gt/label_images/259.png\n",
            "gt/label_images/260.png\n",
            "gt/label_images/261.png\n",
            "gt/label_images/262.png\n",
            "gt/label_images/263.png\n",
            "gt/label_images/265.png\n",
            "gt/label_images/266.png\n",
            "gt/label_images/271.png\n",
            "gt/label_images/272.png\n",
            "gt/label_images/273.png\n",
            "gt/label_images/275.png\n",
            "gt/label_images/276.png\n",
            "gt/label_images/277.png\n",
            "gt/label_images/281.png\n",
            "gt/label_images/283.png\n",
            "gt/label_images/287.png\n",
            "gt/label_images/288.png\n",
            "gt/label_images/289.png\n",
            "gt/label_images/290.png\n",
            "gt/label_images/292.png\n",
            "gt/label_images/294.png\n",
            "gt/label_images/295.png\n",
            "gt/label_images/296.png\n",
            "gt/label_images/298.png\n",
            "gt/label_images/299.png\n",
            "gt/label_images/301.png\n",
            "gt/label_images/302.png\n",
            "gt/label_images/303.png\n",
            "gt/label_images/304.png\n",
            "gt/label_images/305.png\n",
            "gt/label_images/306.png\n",
            "gt/label_images/309.png\n",
            "gt/label_images/310.png\n",
            "gt/label_images/311.png\n",
            "gt/label_images/312.png\n",
            "gt/label_images/313.png\n",
            "gt/label_images/314.png\n",
            "gt/label_images/316.png\n",
            "gt/label_images/318.png\n",
            "gt/label_images/320.png\n",
            "gt/label_images/321.png\n",
            "gt/label_images/322.png\n",
            "gt/label_images/323.png\n",
            "gt/label_images/324.png\n",
            "gt/label_images/325.png\n",
            "gt/label_images/326.png\n",
            "gt/label_images/329.png\n",
            "gt/label_images/330.png\n",
            "gt/label_images/331.png\n",
            "gt/label_images/332.png\n",
            "gt/label_images/334.png\n",
            "gt/label_images/335.png\n",
            "gt/label_images/338.png\n",
            "gt/label_images/339.png\n",
            "gt/label_images/341.png\n",
            "gt/label_images/342.png\n",
            "gt/label_images/344.png\n",
            "gt/label_images/345.png\n",
            "gt/label_images/346.png\n",
            "gt/label_images/347.png\n",
            "gt/label_images/348.png\n",
            "gt/label_images/349.png\n",
            "gt/label_images/351.png\n",
            "gt/label_images/355.png\n",
            "gt/label_images/356.png\n",
            "gt/label_images/361.png\n",
            "gt/label_images/363.png\n",
            "gt/label_images/366.png\n",
            "gt/label_images/367.png\n",
            "gt/label_images/372.png\n",
            "gt/label_images/373.png\n",
            "gt/label_images/375.png\n",
            "gt/label_images/376.png\n",
            "gt/label_images/378.png\n",
            "gt/label_images/380.png\n",
            "gt/label_images/381.png\n",
            "gt/label_images/382.png\n",
            "gt/label_images/383.png\n",
            "gt/label_images/385.png\n",
            "gt/label_images/386.png\n",
            "gt/label_images/388.png\n",
            "gt/label_images/389.png\n",
            "gt/label_images/390.png\n",
            "gt/label_images/391.png\n",
            "gt/label_images/393.png\n",
            "gt/label_images/397.png\n",
            "gt/label_images/398.png\n",
            "gt/label_images/403.png\n",
            "gt/label_images/406.png\n",
            "gt/label_images/408.png\n",
            "gt/label_images/409.png\n",
            "gt/label_images/410.png\n",
            "gt/label_images/411.png\n",
            "gt/label_images/412.png\n",
            "gt/label_images/413.png\n",
            "gt/label_images/414.png\n",
            "gt/label_images/416.png\n",
            "gt/label_images/419.png\n",
            "gt/label_images/420.png\n",
            "gt/label_images/421.png\n",
            "gt/label_images/423.png\n",
            "gt/label_images/424.png\n",
            "gt/label_images/425.png\n",
            "gt/label_images/426.png\n",
            "gt/label_images/427.png\n",
            "gt/label_images/428.png\n",
            "gt/label_images/429.png\n",
            "gt/label_images/430.png\n",
            "gt/label_images/431.png\n",
            "gt/label_images/433.png\n",
            "gt/label_images/434.png\n",
            "gt/label_images/435.png\n",
            "gt/label_images/437.png\n",
            "gt/label_images/438.png\n",
            "gt/label_images/439.png\n",
            "gt/label_images/440.png\n",
            "gt/label_images/442.png\n",
            "gt/label_images/443.png\n",
            "gt/label_images/444.png\n",
            "gt/label_images/445.png\n",
            "gt/label_images/446.png\n",
            "gt/label_images/447.png\n",
            "gt/label_images/451.png\n",
            "gt/label_images/452.png\n",
            "gt/label_images/454.png\n",
            "gt/label_images/455.png\n",
            "gt/label_images/457.png\n",
            "gt/label_images/458.png\n",
            "gt/label_images/460.png\n",
            "gt/label_images/461.png\n",
            "gt/label_images/462.png\n",
            "gt/label_images/463.png\n",
            "gt/label_images/464.png\n",
            "gt/label_images/465.png\n",
            "gt/label_images/467.png\n",
            "gt/label_images/470.png\n",
            "gt/label_images/472.png\n",
            "gt/label_images/473.png\n",
            "gt/label_images/474.png\n",
            "gt/label_images/475.png\n",
            "gt/label_images/476.png\n",
            "gt/label_images/478.png\n",
            "gt/label_images/479.png\n",
            "gt/label_images/480.png\n",
            "gt/label_images/484.png\n",
            "gt/label_images/485.png\n",
            "gt/label_images/488.png\n",
            "gt/label_images/489.png\n",
            "gt/label_images/491.png\n",
            "gt/label_images/493.png\n",
            "gt/label_images/494.png\n",
            "gt/label_images/497.png\n",
            "gt/label_images/498.png\n",
            "gt/label_images/499.png\n",
            "gt/label_images/500.png\n",
            "gt/label_images/501.png\n",
            "gt/label_images/502.png\n",
            "gt/label_images/507.png\n",
            "gt/label_images/508.png\n",
            "gt/label_images/509.png\n",
            "gt/label_images/510.png\n",
            "gt/label_images/512.png\n",
            "gt/label_images/513.png\n",
            "gt/label_images/514.png\n",
            "gt/label_images/515.png\n",
            "gt/label_images/517.png\n",
            "gt/label_images/518.png\n",
            "gt/label_images/521.png\n",
            "gt/label_images/524.png\n",
            "gt/label_images/525.png\n",
            "gt/label_images/526.png\n",
            "gt/label_images/529.png\n",
            "gt/label_images/530.png\n",
            "gt/label_images/531.png\n",
            "gt/label_images/532.png\n",
            "gt/label_images/533.png\n",
            "gt/label_images/535.png\n",
            "gt/label_images/536.png\n",
            "gt/label_images/537.png\n",
            "gt/label_images/538.png\n",
            "gt/label_images/540.png\n",
            "gt/label_images/543.png\n",
            "gt/label_images/544.png\n",
            "gt/label_images/545.png\n",
            "gt/label_images/549.png\n",
            "gt/label_images/551.png\n",
            "gt/label_images/554.png\n",
            "gt/label_images/556.png\n",
            "gt/label_images/558.png\n",
            "gt/label_images/559.png\n",
            "gt/label_images/560.png\n",
            "gt/label_images/561.png\n",
            "gt/label_images/563.png\n",
            "gt/label_images/564.png\n",
            "gt/label_images/565.png\n",
            "gt/label_images/566.png\n",
            "gt/label_images/567.png\n",
            "gt/label_images/568.png\n",
            "gt/label_images/569.png\n",
            "gt/label_images/570.png\n",
            "gt/label_images/572.png\n",
            "gt/label_images/573.png\n",
            "gt/label_images/574.png\n",
            "gt/label_images/576.png\n",
            "gt/label_images/579.png\n",
            "gt/label_images/580.png\n",
            "gt/label_images/582.png\n",
            "gt/label_images/583.png\n",
            "gt/label_images/584.png\n",
            "gt/label_images/585.png\n",
            "gt/label_images/586.png\n",
            "gt/label_images/587.png\n",
            "gt/label_images/588.png\n",
            "gt/label_images/590.png\n",
            "gt/label_images/591.png\n",
            "gt/label_images/592.png\n",
            "gt/label_images/593.png\n",
            "gt/label_images/594.png\n",
            "gt/label_images/596.png\n",
            "gt/label_images/598.png\n",
            "gt/label_images/.ipynb_checkpoints/\n",
            "gt/label_images/original/\n",
            "gt/label_images/original/040.png\n",
            "gt/label_images/original/041.png\n",
            "gt/label_images/original/042.png\n",
            "gt/label_images/original/043.png\n",
            "gt/label_images/original/044.png\n",
            "gt/label_images/original/045.png\n",
            "gt/label_images/original/047.png\n",
            "gt/label_images/original/049.png\n",
            "gt/label_me_xml/\n",
            "gt/label_me_xml/000.xml\n",
            "gt/label_me_xml/001.xml\n",
            "gt/label_me_xml/002.xml\n",
            "gt/label_me_xml/003.xml\n",
            "gt/label_me_xml/004.xml\n",
            "gt/label_me_xml/005.xml\n",
            "gt/label_me_xml/006.xml\n",
            "gt/label_me_xml/008.xml\n",
            "gt/label_me_xml/011.xml\n",
            "gt/label_me_xml/013.xml\n",
            "gt/label_me_xml/014.xml\n",
            "gt/label_me_xml/015.xml\n",
            "gt/label_me_xml/016.xml\n",
            "gt/label_me_xml/018.xml\n",
            "gt/label_me_xml/019.xml\n",
            "gt/label_me_xml/021.xml\n",
            "gt/label_me_xml/022.xml\n",
            "gt/label_me_xml/023.xml\n",
            "gt/label_me_xml/026.xml\n",
            "gt/label_me_xml/028.xml\n",
            "gt/label_me_xml/031.xml\n",
            "gt/label_me_xml/035.xml\n",
            "gt/label_me_xml/038.xml\n",
            "gt/label_me_xml/040.xml\n",
            "gt/label_me_xml/041.xml\n",
            "gt/label_me_xml/042.xml\n",
            "gt/label_me_xml/043.xml\n",
            "gt/label_me_xml/044.xml\n",
            "gt/label_me_xml/045.xml\n",
            "gt/label_me_xml/047.xml\n",
            "gt/label_me_xml/049.xml\n",
            "gt/label_me_xml/051.xml\n",
            "gt/label_me_xml/052.xml\n",
            "gt/label_me_xml/053.xml\n",
            "gt/label_me_xml/055.xml\n",
            "gt/label_me_xml/056.xml\n",
            "gt/label_me_xml/057.xml\n",
            "gt/label_me_xml/058.xml\n",
            "gt/label_me_xml/059.xml\n",
            "gt/label_me_xml/060.xml\n",
            "gt/label_me_xml/062.xml\n",
            "gt/label_me_xml/063.xml\n",
            "gt/label_me_xml/065.xml\n",
            "gt/label_me_xml/068.xml\n",
            "gt/label_me_xml/070.xml\n",
            "gt/label_me_xml/071.xml\n",
            "gt/label_me_xml/073.xml\n",
            "gt/label_me_xml/074.xml\n",
            "gt/label_me_xml/075.xml\n",
            "gt/label_me_xml/077.xml\n",
            "gt/label_me_xml/078.xml\n",
            "gt/label_me_xml/079.xml\n",
            "gt/label_me_xml/080.xml\n",
            "gt/label_me_xml/081.xml\n",
            "gt/label_me_xml/083.xml\n",
            "gt/label_me_xml/086.xml\n",
            "gt/label_me_xml/088.xml\n",
            "gt/label_me_xml/089.xml\n",
            "gt/label_me_xml/092.xml\n",
            "gt/label_me_xml/095.xml\n",
            "gt/label_me_xml/098.xml\n",
            "gt/label_me_xml/099.xml\n",
            "gt/label_me_xml/100.xml\n",
            "gt/label_me_xml/101.xml\n",
            "gt/label_me_xml/102.xml\n",
            "gt/label_me_xml/103.xml\n",
            "gt/label_me_xml/104.xml\n",
            "gt/label_me_xml/106.xml\n",
            "gt/label_me_xml/107.xml\n",
            "gt/label_me_xml/109.xml\n",
            "gt/label_me_xml/110.xml\n",
            "gt/label_me_xml/111.xml\n",
            "gt/label_me_xml/112.xml\n",
            "gt/label_me_xml/113.xml\n",
            "gt/label_me_xml/116.xml\n",
            "gt/label_me_xml/117.xml\n",
            "gt/label_me_xml/118.xml\n",
            "gt/label_me_xml/119.xml\n",
            "gt/label_me_xml/120.xml\n",
            "gt/label_me_xml/121.xml\n",
            "gt/label_me_xml/122.xml\n",
            "gt/label_me_xml/123.xml\n",
            "gt/label_me_xml/124.xml\n",
            "gt/label_me_xml/126.xml\n",
            "gt/label_me_xml/128.xml\n",
            "gt/label_me_xml/130.xml\n",
            "gt/label_me_xml/133.xml\n",
            "gt/label_me_xml/134.xml\n",
            "gt/label_me_xml/135.xml\n",
            "gt/label_me_xml/136.xml\n",
            "gt/label_me_xml/137.xml\n",
            "gt/label_me_xml/138.xml\n",
            "gt/label_me_xml/139.xml\n",
            "gt/label_me_xml/140.xml\n",
            "gt/label_me_xml/141.xml\n",
            "gt/label_me_xml/145.xml\n",
            "gt/label_me_xml/146.xml\n",
            "gt/label_me_xml/147.xml\n",
            "gt/label_me_xml/148.xml\n",
            "gt/label_me_xml/149.xml\n",
            "gt/label_me_xml/150.xml\n",
            "gt/label_me_xml/153.xml\n",
            "gt/label_me_xml/154.xml\n",
            "gt/label_me_xml/155.xml\n",
            "gt/label_me_xml/156.xml\n",
            "gt/label_me_xml/157.xml\n",
            "gt/label_me_xml/158.xml\n",
            "gt/label_me_xml/159.xml\n",
            "gt/label_me_xml/160.xml\n",
            "gt/label_me_xml/161.xml\n",
            "gt/label_me_xml/162.xml\n",
            "gt/label_me_xml/163.xml\n",
            "gt/label_me_xml/164.xml\n",
            "gt/label_me_xml/165.xml\n",
            "gt/label_me_xml/166.xml\n",
            "gt/label_me_xml/167.xml\n",
            "gt/label_me_xml/170.xml\n",
            "gt/label_me_xml/171.xml\n",
            "gt/label_me_xml/172.xml\n",
            "gt/label_me_xml/173.xml\n",
            "gt/label_me_xml/174.xml\n",
            "gt/label_me_xml/175.xml\n",
            "gt/label_me_xml/176.xml\n",
            "gt/label_me_xml/177.xml\n",
            "gt/label_me_xml/178.xml\n",
            "gt/label_me_xml/179.xml\n",
            "gt/label_me_xml/180.xml\n",
            "gt/label_me_xml/181.xml\n",
            "gt/label_me_xml/182.xml\n",
            "gt/label_me_xml/185.xml\n",
            "gt/label_me_xml/186.xml\n",
            "gt/label_me_xml/188.xml\n",
            "gt/label_me_xml/190.xml\n",
            "gt/label_me_xml/192.xml\n",
            "gt/label_me_xml/193.xml\n",
            "gt/label_me_xml/194.xml\n",
            "gt/label_me_xml/195.xml\n",
            "gt/label_me_xml/198.xml\n",
            "gt/label_me_xml/199.xml\n",
            "gt/label_me_xml/200.xml\n",
            "gt/label_me_xml/202.xml\n",
            "gt/label_me_xml/204.xml\n",
            "gt/label_me_xml/206.xml\n",
            "gt/label_me_xml/207.xml\n",
            "gt/label_me_xml/208.xml\n",
            "gt/label_me_xml/209.xml\n",
            "gt/label_me_xml/213.xml\n",
            "gt/label_me_xml/214.xml\n",
            "gt/label_me_xml/215.xml\n",
            "gt/label_me_xml/216.xml\n",
            "gt/label_me_xml/217.xml\n",
            "gt/label_me_xml/219.xml\n",
            "gt/label_me_xml/220.xml\n",
            "gt/label_me_xml/221.xml\n",
            "gt/label_me_xml/222.xml\n",
            "gt/label_me_xml/223.xml\n",
            "gt/label_me_xml/225.xml\n",
            "gt/label_me_xml/226.xml\n",
            "gt/label_me_xml/228.xml\n",
            "gt/label_me_xml/229.xml\n",
            "gt/label_me_xml/230.xml\n",
            "gt/label_me_xml/232.xml\n",
            "gt/label_me_xml/233.xml\n",
            "gt/label_me_xml/234.xml\n",
            "gt/label_me_xml/235.xml\n",
            "gt/label_me_xml/236.xml\n",
            "gt/label_me_xml/237.xml\n",
            "gt/label_me_xml/238.xml\n",
            "gt/label_me_xml/239.xml\n",
            "gt/label_me_xml/240.xml\n",
            "gt/label_me_xml/243.xml\n",
            "gt/label_me_xml/244.xml\n",
            "gt/label_me_xml/246.xml\n",
            "gt/label_me_xml/248.xml\n",
            "gt/label_me_xml/250.xml\n",
            "gt/label_me_xml/251.xml\n",
            "gt/label_me_xml/252.xml\n",
            "gt/label_me_xml/255.xml\n",
            "gt/label_me_xml/257.xml\n",
            "gt/label_me_xml/258.xml\n",
            "gt/label_me_xml/259.xml\n",
            "gt/label_me_xml/260.xml\n",
            "gt/label_me_xml/261.xml\n",
            "gt/label_me_xml/262.xml\n",
            "gt/label_me_xml/263.xml\n",
            "gt/label_me_xml/265.xml\n",
            "gt/label_me_xml/266.xml\n",
            "gt/label_me_xml/271.xml\n",
            "gt/label_me_xml/272.xml\n",
            "gt/label_me_xml/273.xml\n",
            "gt/label_me_xml/275.xml\n",
            "gt/label_me_xml/276.xml\n",
            "gt/label_me_xml/277.xml\n",
            "gt/label_me_xml/281.xml\n",
            "gt/label_me_xml/283.xml\n",
            "gt/label_me_xml/287.xml\n",
            "gt/label_me_xml/288.xml\n",
            "gt/label_me_xml/289.xml\n",
            "gt/label_me_xml/290.xml\n",
            "gt/label_me_xml/292.xml\n",
            "gt/label_me_xml/294.xml\n",
            "gt/label_me_xml/295.xml\n",
            "gt/label_me_xml/296.xml\n",
            "gt/label_me_xml/298.xml\n",
            "gt/label_me_xml/299.xml\n",
            "gt/label_me_xml/301.xml\n",
            "gt/label_me_xml/302.xml\n",
            "gt/label_me_xml/303.xml\n",
            "gt/label_me_xml/304.xml\n",
            "gt/label_me_xml/305.xml\n",
            "gt/label_me_xml/306.xml\n",
            "gt/label_me_xml/309.xml\n",
            "gt/label_me_xml/310.xml\n",
            "gt/label_me_xml/311.xml\n",
            "gt/label_me_xml/312.xml\n",
            "gt/label_me_xml/313.xml\n",
            "gt/label_me_xml/314.xml\n",
            "gt/label_me_xml/316.xml\n",
            "gt/label_me_xml/318.xml\n",
            "gt/label_me_xml/320.xml\n",
            "gt/label_me_xml/321.xml\n",
            "gt/label_me_xml/322.xml\n",
            "gt/label_me_xml/323.xml\n",
            "gt/label_me_xml/324.xml\n",
            "gt/label_me_xml/325.xml\n",
            "gt/label_me_xml/326.xml\n",
            "gt/label_me_xml/329.xml\n",
            "gt/label_me_xml/330.xml\n",
            "gt/label_me_xml/331.xml\n",
            "gt/label_me_xml/332.xml\n",
            "gt/label_me_xml/334.xml\n",
            "gt/label_me_xml/335.xml\n",
            "gt/label_me_xml/338.xml\n",
            "gt/label_me_xml/339.xml\n",
            "gt/label_me_xml/341.xml\n",
            "gt/label_me_xml/342.xml\n",
            "gt/label_me_xml/344.xml\n",
            "gt/label_me_xml/345.xml\n",
            "gt/label_me_xml/346.xml\n",
            "gt/label_me_xml/347.xml\n",
            "gt/label_me_xml/348.xml\n",
            "gt/label_me_xml/349.xml\n",
            "gt/label_me_xml/351.xml\n",
            "gt/label_me_xml/355.xml\n",
            "gt/label_me_xml/356.xml\n",
            "gt/label_me_xml/361.xml\n",
            "gt/label_me_xml/363.xml\n",
            "gt/label_me_xml/366.xml\n",
            "gt/label_me_xml/367.xml\n",
            "gt/label_me_xml/372.xml\n",
            "gt/label_me_xml/373.xml\n",
            "gt/label_me_xml/375.xml\n",
            "gt/label_me_xml/376.xml\n",
            "gt/label_me_xml/378.xml\n",
            "gt/label_me_xml/380.xml\n",
            "gt/label_me_xml/381.xml\n",
            "gt/label_me_xml/382.xml\n",
            "gt/label_me_xml/383.xml\n",
            "gt/label_me_xml/385.xml\n",
            "gt/label_me_xml/386.xml\n",
            "gt/label_me_xml/388.xml\n",
            "gt/label_me_xml/390.xml\n",
            "gt/label_me_xml/391.xml\n",
            "gt/label_me_xml/393.xml\n",
            "gt/label_me_xml/397.xml\n",
            "gt/label_me_xml/398.xml\n",
            "gt/label_me_xml/403.xml\n",
            "gt/label_me_xml/406.xml\n",
            "gt/label_me_xml/408.xml\n",
            "gt/label_me_xml/409.xml\n",
            "gt/label_me_xml/410.xml\n",
            "gt/label_me_xml/411.xml\n",
            "gt/label_me_xml/412.xml\n",
            "gt/label_me_xml/413.xml\n",
            "gt/label_me_xml/414.xml\n",
            "gt/label_me_xml/416.xml\n",
            "gt/label_me_xml/419.xml\n",
            "gt/label_me_xml/420.xml\n",
            "gt/label_me_xml/421.xml\n",
            "gt/label_me_xml/423.xml\n",
            "gt/label_me_xml/424.xml\n",
            "gt/label_me_xml/425.xml\n",
            "gt/label_me_xml/426.xml\n",
            "gt/label_me_xml/427.xml\n",
            "gt/label_me_xml/428.xml\n",
            "gt/label_me_xml/429.xml\n",
            "gt/label_me_xml/430.xml\n",
            "gt/label_me_xml/431.xml\n",
            "gt/label_me_xml/433.xml\n",
            "gt/label_me_xml/434.xml\n",
            "gt/label_me_xml/435.xml\n",
            "gt/label_me_xml/437.xml\n",
            "gt/label_me_xml/438.xml\n",
            "gt/label_me_xml/439.xml\n",
            "gt/label_me_xml/440.xml\n",
            "gt/label_me_xml/442.xml\n",
            "gt/label_me_xml/443.xml\n",
            "gt/label_me_xml/444.xml\n",
            "gt/label_me_xml/445.xml\n",
            "gt/label_me_xml/446.xml\n",
            "gt/label_me_xml/447.xml\n",
            "gt/label_me_xml/451.xml\n",
            "gt/label_me_xml/452.xml\n",
            "gt/label_me_xml/454.xml\n",
            "gt/label_me_xml/455.xml\n",
            "gt/label_me_xml/457.xml\n",
            "gt/label_me_xml/458.xml\n",
            "gt/label_me_xml/460.xml\n",
            "gt/label_me_xml/461.xml\n",
            "gt/label_me_xml/462.xml\n",
            "gt/label_me_xml/463.xml\n",
            "gt/label_me_xml/464.xml\n",
            "gt/label_me_xml/465.xml\n",
            "gt/label_me_xml/467.xml\n",
            "gt/label_me_xml/470.xml\n",
            "gt/label_me_xml/472.xml\n",
            "gt/label_me_xml/473.xml\n",
            "gt/label_me_xml/474.xml\n",
            "gt/label_me_xml/475.xml\n",
            "gt/label_me_xml/476.xml\n",
            "gt/label_me_xml/478.xml\n",
            "gt/label_me_xml/479.xml\n",
            "gt/label_me_xml/480.xml\n",
            "gt/label_me_xml/484.xml\n",
            "gt/label_me_xml/485.xml\n",
            "gt/label_me_xml/488.xml\n",
            "gt/label_me_xml/489.xml\n",
            "gt/label_me_xml/491.xml\n",
            "gt/label_me_xml/493.xml\n",
            "gt/label_me_xml/494.xml\n",
            "gt/label_me_xml/497.xml\n",
            "gt/label_me_xml/498.xml\n",
            "gt/label_me_xml/499.xml\n",
            "gt/label_me_xml/500.xml\n",
            "gt/label_me_xml/501.xml\n",
            "gt/label_me_xml/502.xml\n",
            "gt/label_me_xml/507.xml\n",
            "gt/label_me_xml/508.xml\n",
            "gt/label_me_xml/509.xml\n",
            "gt/label_me_xml/510.xml\n",
            "gt/label_me_xml/512.xml\n",
            "gt/label_me_xml/513.xml\n",
            "gt/label_me_xml/514.xml\n",
            "gt/label_me_xml/515.xml\n",
            "gt/label_me_xml/517.xml\n",
            "gt/label_me_xml/518.xml\n",
            "gt/label_me_xml/521.xml\n",
            "gt/label_me_xml/524.xml\n",
            "gt/label_me_xml/525.xml\n",
            "gt/label_me_xml/526.xml\n",
            "gt/label_me_xml/529.xml\n",
            "gt/label_me_xml/530.xml\n",
            "gt/label_me_xml/531.xml\n",
            "gt/label_me_xml/532.xml\n",
            "gt/label_me_xml/533.xml\n",
            "gt/label_me_xml/535.xml\n",
            "gt/label_me_xml/536.xml\n",
            "gt/label_me_xml/537.xml\n",
            "gt/label_me_xml/538.xml\n",
            "gt/label_me_xml/540.xml\n",
            "gt/label_me_xml/543.xml\n",
            "gt/label_me_xml/544.xml\n",
            "gt/label_me_xml/545.xml\n",
            "gt/label_me_xml/549.xml\n",
            "gt/label_me_xml/551.xml\n",
            "gt/label_me_xml/554.xml\n",
            "gt/label_me_xml/556.xml\n",
            "gt/label_me_xml/558.xml\n",
            "gt/label_me_xml/559.xml\n",
            "gt/label_me_xml/560.xml\n",
            "gt/label_me_xml/561.xml\n",
            "gt/label_me_xml/563.xml\n",
            "gt/label_me_xml/564.xml\n",
            "gt/label_me_xml/565.xml\n",
            "gt/label_me_xml/566.xml\n",
            "gt/label_me_xml/567.xml\n",
            "gt/label_me_xml/568.xml\n",
            "gt/label_me_xml/569.xml\n",
            "gt/label_me_xml/570.xml\n",
            "gt/label_me_xml/572.xml\n",
            "gt/label_me_xml/573.xml\n",
            "gt/label_me_xml/574.xml\n",
            "gt/label_me_xml/576.xml\n",
            "gt/label_me_xml/579.xml\n",
            "gt/label_me_xml/580.xml\n",
            "gt/label_me_xml/582.xml\n",
            "gt/label_me_xml/583.xml\n",
            "gt/label_me_xml/584.xml\n",
            "gt/label_me_xml/585.xml\n",
            "gt/label_me_xml/586.xml\n",
            "gt/label_me_xml/587.xml\n",
            "gt/label_me_xml/588.xml\n",
            "gt/label_me_xml/590.xml\n",
            "gt/label_me_xml/591.xml\n",
            "gt/label_me_xml/592.xml\n",
            "gt/label_me_xml/593.xml\n",
            "gt/label_me_xml/594.xml\n",
            "gt/label_me_xml/596.xml\n",
            "gt/label_me_xml/598.xml\n",
            "images/\n",
            "images/000.jpg\n",
            "images/001.jpg\n",
            "images/002.jpg\n",
            "images/003.jpg\n",
            "images/004.jpg\n",
            "images/005.jpg\n",
            "images/006.jpg\n",
            "images/008.jpg\n",
            "images/011.jpg\n",
            "images/013.jpg\n",
            "images/014.jpg\n",
            "images/015.jpg\n",
            "images/016.jpg\n",
            "images/018.jpg\n",
            "images/019.jpg\n",
            "images/021.jpg\n",
            "images/022.jpg\n",
            "images/023.jpg\n",
            "images/026.jpg\n",
            "images/028.jpg\n",
            "images/031.jpg\n",
            "images/035.jpg\n",
            "images/038.jpg\n",
            "images/040.jpg\n",
            "images/041.jpg\n",
            "images/042.jpg\n",
            "images/043.jpg\n",
            "images/044.jpg\n",
            "images/045.jpg\n",
            "images/047.jpg\n",
            "images/049.jpg\n",
            "images/051.jpg\n",
            "images/052.jpg\n",
            "images/053.jpg\n",
            "images/055.jpg\n",
            "images/056.jpg\n",
            "images/057.jpg\n",
            "images/058.jpg\n",
            "images/059.jpg\n",
            "images/060.jpg\n",
            "images/062.jpg\n",
            "images/063.jpg\n",
            "images/065.jpg\n",
            "images/068.jpg\n",
            "images/070.jpg\n",
            "images/071.jpg\n",
            "images/073.jpg\n",
            "images/074.jpg\n",
            "images/075.jpg\n",
            "images/077.jpg\n",
            "images/078.jpg\n",
            "images/079.jpg\n",
            "images/080.jpg\n",
            "images/081.jpg\n",
            "images/083.jpg\n",
            "images/086.jpg\n",
            "images/088.jpg\n",
            "images/089.jpg\n",
            "images/092.jpg\n",
            "images/095.jpg\n",
            "images/098.jpg\n",
            "images/099.jpg\n",
            "images/100.jpg\n",
            "images/101.jpg\n",
            "images/102.jpg\n",
            "images/103.jpg\n",
            "images/104.jpg\n",
            "images/106.jpg\n",
            "images/107.jpg\n",
            "images/109.jpg\n",
            "images/110.jpg\n",
            "images/111.jpg\n",
            "images/112.jpg\n",
            "images/113.jpg\n",
            "images/116.jpg\n",
            "images/117.jpg\n",
            "images/118.jpg\n",
            "images/119.jpg\n",
            "images/120.jpg\n",
            "images/121.jpg\n",
            "images/122.jpg\n",
            "images/123.jpg\n",
            "images/124.jpg\n",
            "images/126.jpg\n",
            "images/128.jpg\n",
            "images/130.jpg\n",
            "images/133.jpg\n",
            "images/134.jpg\n",
            "images/135.jpg\n",
            "images/136.jpg\n",
            "images/137.jpg\n",
            "images/138.jpg\n",
            "images/139.jpg\n",
            "images/140.jpg\n",
            "images/141.jpg\n",
            "images/145.jpg\n",
            "images/146.jpg\n",
            "images/147.jpg\n",
            "images/148.jpg\n",
            "images/149.jpg\n",
            "images/150.jpg\n",
            "images/153.jpg\n",
            "images/154.jpg\n",
            "images/155.jpg\n",
            "images/156.jpg\n",
            "images/157.jpg\n",
            "images/158.jpg\n",
            "images/159.jpg\n",
            "images/160.jpg\n",
            "images/161.jpg\n",
            "images/162.jpg\n",
            "images/163.jpg\n",
            "images/164.jpg\n",
            "images/165.jpg\n",
            "images/166.jpg\n",
            "images/167.jpg\n",
            "images/170.jpg\n",
            "images/171.jpg\n",
            "images/172.jpg\n",
            "images/173.jpg\n",
            "images/174.jpg\n",
            "images/175.jpg\n",
            "images/176.jpg\n",
            "images/177.jpg\n",
            "images/178.jpg\n",
            "images/179.jpg\n",
            "images/180.jpg\n",
            "images/181.jpg\n",
            "images/182.jpg\n",
            "images/185.jpg\n",
            "images/186.jpg\n",
            "images/188.jpg\n",
            "images/190.jpg\n",
            "images/192.jpg\n",
            "images/193.jpg\n",
            "images/194.jpg\n",
            "images/195.jpg\n",
            "images/198.jpg\n",
            "images/199.jpg\n",
            "images/200.jpg\n",
            "images/202.jpg\n",
            "images/204.jpg\n",
            "images/206.jpg\n",
            "images/207.jpg\n",
            "images/208.jpg\n",
            "images/209.jpg\n",
            "images/213.jpg\n",
            "images/214.jpg\n",
            "images/215.jpg\n",
            "images/216.jpg\n",
            "images/217.jpg\n",
            "images/219.jpg\n",
            "images/220.jpg\n",
            "images/221.jpg\n",
            "images/222.jpg\n",
            "images/223.jpg\n",
            "images/225.jpg\n",
            "images/226.jpg\n",
            "images/228.jpg\n",
            "images/229.jpg\n",
            "images/230.jpg\n",
            "images/232.jpg\n",
            "images/233.jpg\n",
            "images/234.jpg\n",
            "images/235.jpg\n",
            "images/236.jpg\n",
            "images/237.jpg\n",
            "images/238.jpg\n",
            "images/239.jpg\n",
            "images/240.jpg\n",
            "images/243.jpg\n",
            "images/244.jpg\n",
            "images/246.jpg\n",
            "images/248.jpg\n",
            "images/250.jpg\n",
            "images/251.jpg\n",
            "images/252.jpg\n",
            "images/255.jpg\n",
            "images/257.jpg\n",
            "images/258.jpg\n",
            "images/259.jpg\n",
            "images/260.jpg\n",
            "images/261.jpg\n",
            "images/262.jpg\n",
            "images/263.jpg\n",
            "images/265.jpg\n",
            "images/266.jpg\n",
            "images/271.jpg\n",
            "images/272.jpg\n",
            "images/273.jpg\n",
            "images/275.jpg\n",
            "images/276.jpg\n",
            "images/277.jpg\n",
            "images/281.jpg\n",
            "images/283.jpg\n",
            "images/287.jpg\n",
            "images/288.jpg\n",
            "images/289.jpg\n",
            "images/290.jpg\n",
            "images/292.jpg\n",
            "images/294.jpg\n",
            "images/295.jpg\n",
            "images/296.jpg\n",
            "images/298.jpg\n",
            "images/299.jpg\n",
            "images/301.jpg\n",
            "images/302.jpg\n",
            "images/303.jpg\n",
            "images/304.jpg\n",
            "images/305.jpg\n",
            "images/306.jpg\n",
            "images/309.jpg\n",
            "images/310.jpg\n",
            "images/311.jpg\n",
            "images/312.jpg\n",
            "images/313.jpg\n",
            "images/314.jpg\n",
            "images/316.jpg\n",
            "images/318.jpg\n",
            "images/320.jpg\n",
            "images/321.jpg\n",
            "images/322.jpg\n",
            "images/323.jpg\n",
            "images/324.jpg\n",
            "images/325.jpg\n",
            "images/326.jpg\n",
            "images/329.jpg\n",
            "images/330.jpg\n",
            "images/331.jpg\n",
            "images/332.jpg\n",
            "images/334.jpg\n",
            "images/335.jpg\n",
            "images/338.jpg\n",
            "images/339.jpg\n",
            "images/341.jpg\n",
            "images/342.jpg\n",
            "images/344.jpg\n",
            "images/345.jpg\n",
            "images/346.jpg\n",
            "images/347.jpg\n",
            "images/348.jpg\n",
            "images/349.jpg\n",
            "images/351.jpg\n",
            "images/355.jpg\n",
            "images/356.jpg\n",
            "images/361.jpg\n",
            "images/363.jpg\n",
            "images/366.jpg\n",
            "images/367.jpg\n",
            "images/372.jpg\n",
            "images/373.jpg\n",
            "images/375.jpg\n",
            "images/376.jpg\n",
            "images/378.jpg\n",
            "images/380.jpg\n",
            "images/381.jpg\n",
            "images/382.jpg\n",
            "images/383.jpg\n",
            "images/385.jpg\n",
            "images/386.jpg\n",
            "images/388.jpg\n",
            "images/389.jpg\n",
            "images/390.jpg\n",
            "images/391.jpg\n",
            "images/393.jpg\n",
            "images/397.jpg\n",
            "images/398.jpg\n",
            "images/403.jpg\n",
            "images/406.jpg\n",
            "images/408.jpg\n",
            "images/409.jpg\n",
            "images/410.jpg\n",
            "images/411.jpg\n",
            "images/412.jpg\n",
            "images/413.jpg\n",
            "images/414.jpg\n",
            "images/416.jpg\n",
            "images/419.jpg\n",
            "images/420.jpg\n",
            "images/421.jpg\n",
            "images/423.jpg\n",
            "images/424.jpg\n",
            "images/425.jpg\n",
            "images/426.jpg\n",
            "images/427.jpg\n",
            "images/428.jpg\n",
            "images/429.jpg\n",
            "images/430.jpg\n",
            "images/431.jpg\n",
            "images/433.jpg\n",
            "images/434.jpg\n",
            "images/435.jpg\n",
            "images/437.jpg\n",
            "images/438.jpg\n",
            "images/439.jpg\n",
            "images/440.jpg\n",
            "images/442.jpg\n",
            "images/443.jpg\n",
            "images/444.jpg\n",
            "images/445.jpg\n",
            "images/446.jpg\n",
            "images/447.jpg\n",
            "images/451.jpg\n",
            "images/452.jpg\n",
            "images/454.jpg\n",
            "images/455.jpg\n",
            "images/457.jpg\n",
            "images/458.jpg\n",
            "images/460.jpg\n",
            "images/461.jpg\n",
            "images/462.jpg\n",
            "images/463.jpg\n",
            "images/464.jpg\n",
            "images/465.jpg\n",
            "images/467.jpg\n",
            "images/470.jpg\n",
            "images/472.jpg\n",
            "images/473.jpg\n",
            "images/474.jpg\n",
            "images/475.jpg\n",
            "images/476.jpg\n",
            "images/478.jpg\n",
            "images/479.jpg\n",
            "images/480.jpg\n",
            "images/484.jpg\n",
            "images/485.jpg\n",
            "images/488.jpg\n",
            "images/489.jpg\n",
            "images/491.jpg\n",
            "images/493.jpg\n",
            "images/494.jpg\n",
            "images/497.jpg\n",
            "images/498.jpg\n",
            "images/499.jpg\n",
            "images/500.jpg\n",
            "images/501.jpg\n",
            "images/502.jpg\n",
            "images/507.jpg\n",
            "images/508.jpg\n",
            "images/509.jpg\n",
            "images/510.jpg\n",
            "images/512.jpg\n",
            "images/513.jpg\n",
            "images/514.jpg\n",
            "images/515.jpg\n",
            "images/517.jpg\n",
            "images/518.jpg\n",
            "images/521.jpg\n",
            "images/524.jpg\n",
            "images/525.jpg\n",
            "images/526.jpg\n",
            "images/529.jpg\n",
            "images/530.jpg\n",
            "images/531.jpg\n",
            "images/532.jpg\n",
            "images/533.jpg\n",
            "images/535.jpg\n",
            "images/536.jpg\n",
            "images/537.jpg\n",
            "images/538.jpg\n",
            "images/540.jpg\n",
            "images/543.jpg\n",
            "images/544.jpg\n",
            "images/545.jpg\n",
            "images/549.jpg\n",
            "images/551.jpg\n",
            "images/554.jpg\n",
            "images/556.jpg\n",
            "images/558.jpg\n",
            "images/559.jpg\n",
            "images/560.jpg\n",
            "images/561.jpg\n",
            "images/563.jpg\n",
            "images/564.jpg\n",
            "images/565.jpg\n",
            "images/566.jpg\n",
            "images/567.jpg\n",
            "images/568.jpg\n",
            "images/569.jpg\n",
            "images/570.jpg\n",
            "images/572.jpg\n",
            "images/573.jpg\n",
            "images/574.jpg\n",
            "images/576.jpg\n",
            "images/579.jpg\n",
            "images/580.jpg\n",
            "images/582.jpg\n",
            "images/583.jpg\n",
            "images/584.jpg\n",
            "images/585.jpg\n",
            "images/586.jpg\n",
            "images/587.jpg\n",
            "images/588.jpg\n",
            "images/590.jpg\n",
            "images/591.jpg\n",
            "images/592.jpg\n",
            "images/593.jpg\n",
            "images/594.jpg\n",
            "images/596.jpg\n",
            "images/598.jpg\n",
            "images/.ipynb_checkpoints/\n",
            "images/original/\n",
            "images/original/040.jpg\n",
            "images/original/041.jpg\n",
            "images/original/042.jpg\n",
            "images/original/043.jpg\n",
            "images/original/044.jpg\n",
            "images/original/045.jpg\n",
            "images/original/047.jpg\n",
            "images/original/049.jpg\n",
            "keras-deeplab-v3-plus/\n",
            "keras-deeplab-v3-plus/.gitignore\n",
            "keras-deeplab-v3-plus/LICENSE\n",
            "keras-deeplab-v3-plus/README.md\n",
            "keras-deeplab-v3-plus/extract_weights.py\n",
            "keras-deeplab-v3-plus/load_weights.py\n",
            "keras-deeplab-v3-plus/model.py\n",
            "keras-deeplab-v3-plus/requirements.txt\n",
            "keras-deeplab-v3-plus/.git/\n",
            "keras-deeplab-v3-plus/.git/HEAD\n",
            "keras-deeplab-v3-plus/.git/config\n",
            "keras-deeplab-v3-plus/.git/description\n",
            "keras-deeplab-v3-plus/.git/index\n",
            "keras-deeplab-v3-plus/.git/packed-refs\n",
            "keras-deeplab-v3-plus/.git/branches/\n",
            "keras-deeplab-v3-plus/.git/hooks/\n",
            "keras-deeplab-v3-plus/.git/hooks/applypatch-msg.sample\n",
            "keras-deeplab-v3-plus/.git/hooks/commit-msg.sample\n",
            "keras-deeplab-v3-plus/.git/hooks/fsmonitor-watchman.sample\n",
            "keras-deeplab-v3-plus/.git/hooks/post-update.sample\n",
            "keras-deeplab-v3-plus/.git/hooks/pre-applypatch.sample\n",
            "keras-deeplab-v3-plus/.git/hooks/pre-commit.sample\n",
            "keras-deeplab-v3-plus/.git/hooks/pre-push.sample\n",
            "keras-deeplab-v3-plus/.git/hooks/pre-rebase.sample\n",
            "keras-deeplab-v3-plus/.git/hooks/pre-receive.sample\n",
            "keras-deeplab-v3-plus/.git/hooks/prepare-commit-msg.sample\n",
            "keras-deeplab-v3-plus/.git/hooks/update.sample\n",
            "keras-deeplab-v3-plus/.git/info/\n",
            "keras-deeplab-v3-plus/.git/info/exclude\n",
            "keras-deeplab-v3-plus/.git/logs/\n",
            "keras-deeplab-v3-plus/.git/logs/HEAD\n",
            "keras-deeplab-v3-plus/.git/logs/refs/\n",
            "keras-deeplab-v3-plus/.git/logs/refs/heads/\n",
            "keras-deeplab-v3-plus/.git/logs/refs/heads/master\n",
            "keras-deeplab-v3-plus/.git/logs/refs/remotes/\n",
            "keras-deeplab-v3-plus/.git/logs/refs/remotes/origin/\n",
            "keras-deeplab-v3-plus/.git/logs/refs/remotes/origin/HEAD\n",
            "keras-deeplab-v3-plus/.git/objects/\n",
            "keras-deeplab-v3-plus/.git/objects/info/\n",
            "keras-deeplab-v3-plus/.git/objects/pack/\n",
            "keras-deeplab-v3-plus/.git/objects/pack/pack-dfba5d8254f7b9520b44a78f319997dcb988e645.idx\n",
            "keras-deeplab-v3-plus/.git/objects/pack/pack-dfba5d8254f7b9520b44a78f319997dcb988e645.pack\n",
            "keras-deeplab-v3-plus/.git/refs/\n",
            "keras-deeplab-v3-plus/.git/refs/heads/\n",
            "keras-deeplab-v3-plus/.git/refs/heads/master\n",
            "keras-deeplab-v3-plus/.git/refs/remotes/\n",
            "keras-deeplab-v3-plus/.git/refs/remotes/origin/\n",
            "keras-deeplab-v3-plus/.git/refs/remotes/origin/HEAD\n",
            "keras-deeplab-v3-plus/.git/refs/tags/\n",
            "keras-deeplab-v3-plus/.ipynb_checkpoints/\n",
            "keras-deeplab-v3-plus/.ipynb_checkpoints/Untitled-checkpoint.ipynb\n",
            "keras-deeplab-v3-plus/.ipynb_checkpoints/model-Copy1-checkpoint.py\n",
            "keras-deeplab-v3-plus/.ipynb_checkpoints/model-checkpoint.py\n",
            "keras-deeplab-v3-plus/.ipynb_checkpoints/test-checkpoint.ipynb\n",
            "keras-deeplab-v3-plus/__pycache__/\n",
            "keras-deeplab-v3-plus/__pycache__/model.cpython-37.pyc\n",
            "keras-deeplab-v3-plus/imgs/\n",
            "keras-deeplab-v3-plus/imgs/image1.jpg\n",
            "keras-deeplab-v3-plus/imgs/image2.jpg\n",
            "keras-deeplab-v3-plus/imgs/image3.jpg\n",
            "keras-deeplab-v3-plus/imgs/my_seg_results1.png\n",
            "keras-deeplab-v3-plus/imgs/my_seg_results1_OS16.png\n",
            "keras-deeplab-v3-plus/imgs/my_seg_results1_OS8.png\n",
            "keras-deeplab-v3-plus/imgs/my_seg_results2_OS16.png\n",
            "keras-deeplab-v3-plus/imgs/my_seg_results2_OS8.png\n",
            "keras-deeplab-v3-plus/imgs/my_seg_results3.png\n",
            "keras-deeplab-v3-plus/imgs/my_seg_results3_OS16.png\n",
            "keras-deeplab-v3-plus/imgs/my_seg_results3_OS8.png\n",
            "keras-deeplab-v3-plus/imgs/seg_results1.png\n",
            "keras-deeplab-v3-plus/imgs/seg_results2.png\n",
            "keras-deeplab-v3-plus/imgs/seg_results3.png\n",
            "metadata/\n",
            "metadata/.ipynb_checkpoints/\n",
            "tables/\n",
            "tables/table_attributes_actv_0.csv\n",
            "tables/table_attributes_actv_16.csv\n",
            "tables/table_attributes_actv_3.csv\n",
            "tables/table_attributes_actv_last.csv\n",
            "tables/.ipynb_checkpoints/\n",
            "trained_models/\n",
            "trained_models/trained_model_030621/\n",
            "trained_models/trained_model_030621/keras_metadata.pb\n",
            "trained_models/trained_model_030621/saved_model.pb\n",
            "trained_models/trained_model_030621/assets/\n",
            "trained_models/trained_model_030621/variables/\n",
            "trained_models/trained_model_030621/variables/variables.data-00000-of-00001\n",
            "trained_models/trained_model_030621/variables/variables.index\n",
            "trained_models/trained_model_030621_2/\n",
            "trained_models/trained_model_030621_2/keras_metadata.pb\n",
            "trained_models/trained_model_030621_2/saved_model.pb\n",
            "trained_models/trained_model_030621_2/assets/\n",
            "trained_models/trained_model_030621_2/variables/\n",
            "trained_models/trained_model_030621_2/variables/variables.data-00000-of-00001\n",
            "trained_models/trained_model_030621_2/variables/variables.index\n",
            "trained_models/trained_model_030621_3/\n",
            "trained_models/trained_model_030621_3/keras_metadata.pb\n",
            "trained_models/trained_model_030621_3/saved_model.pb\n",
            "trained_models/trained_model_030621_3/assets/\n",
            "trained_models/trained_model_030621_3/variables/\n",
            "trained_models/trained_model_030621_3/variables/variables.data-00000-of-00001\n",
            "trained_models/trained_model_030621_3/variables/variables.index\n",
            "trained_models/trained_model_030621_inceptionv3/\n",
            "trained_models/trained_model_030621_inceptionv3/keras_metadata.pb\n",
            "trained_models/trained_model_030621_inceptionv3/saved_model.pb\n",
            "trained_models/trained_model_030621_inceptionv3/assets/\n",
            "trained_models/trained_model_030621_inceptionv3/variables/\n",
            "trained_models/trained_model_030621_inceptionv3/variables/variables.data-00000-of-00001\n",
            "trained_models/trained_model_030621_inceptionv3/variables/variables.index\n",
            "trained_models/trained_model_060621_deeplabv3/\n",
            "trained_models/trained_model_060621_deeplabv3/keras_metadata.pb\n",
            "trained_models/trained_model_060621_deeplabv3/saved_model.pb\n",
            "trained_models/trained_model_060621_deeplabv3/assets/\n",
            "trained_models/trained_model_060621_deeplabv3/variables/\n",
            "trained_models/trained_model_060621_deeplabv3/variables/variables.data-00000-of-00001\n",
            "trained_models/trained_model_060621_deeplabv3/variables/variables.index\n",
            "trained_models/trained_model_060621_deeplabv3_nocut/\n",
            "trained_models/trained_model_060621_deeplabv3_nocut/keras_metadata.pb\n",
            "trained_models/trained_model_060621_deeplabv3_nocut/saved_model.pb\n",
            "trained_models/trained_model_060621_deeplabv3_nocut/training_log_nocut.txt\n",
            "trained_models/trained_model_060621_deeplabv3_nocut/assets/\n",
            "trained_models/trained_model_060621_deeplabv3_nocut/variables/\n",
            "trained_models/trained_model_060621_deeplabv3_nocut/variables/variables.data-00000-of-00001\n",
            "trained_models/trained_model_060621_deeplabv3_nocut/variables/variables.index\n",
            "trained_models/trained_model_060621_resnet50/\n",
            "trained_models/trained_model_060621_resnet50/keras_metadata.pb\n",
            "trained_models/trained_model_060621_resnet50/saved_model.pb\n",
            "trained_models/trained_model_060621_resnet50/assets/\n",
            "trained_models/trained_model_060621_resnet50/variables/\n",
            "trained_models/trained_model_060621_resnet50/variables/variables.data-00000-of-00001\n",
            "trained_models/trained_model_060621_resnet50/variables/variables.index\n",
            "trained_models/trained_model_070621_deeplabv3_cutting/\n",
            "trained_models/trained_model_070621_deeplabv3_cutting/deeplab_cutting_training_log.txt\n",
            "trained_models/trained_model_070621_deeplabv3_cutting/keras_metadata.pb\n",
            "trained_models/trained_model_070621_deeplabv3_cutting/saved_model.pb\n",
            "trained_models/trained_model_070621_deeplabv3_cutting/assets/\n",
            "trained_models/trained_model_070621_deeplabv3_cutting/variables/\n",
            "trained_models/trained_model_070621_deeplabv3_cutting/variables/variables.data-00000-of-00001\n",
            "trained_models/trained_model_070621_deeplabv3_cutting/variables/variables.index\n",
            "trained_models/trained_model_120621_deeplabv3_crop/\n",
            "trained_models/trained_model_120621_deeplabv3_crop/keras_metadata.pb\n",
            "trained_models/trained_model_120621_deeplabv3_crop/saved_model.pb\n",
            "trained_models/trained_model_120621_deeplabv3_crop/assets/\n",
            "trained_models/trained_model_120621_deeplabv3_crop/variables/\n",
            "trained_models/trained_model_120621_deeplabv3_crop/variables/variables.data-00000-of-00001\n",
            "trained_models/trained_model_120621_deeplabv3_crop/variables/variables.index\n",
            "\n",
            "sent 3.71G bytes  received 30.92K bytes  7.83M bytes/sec\n",
            "total size is 3.71G  speedup is 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRh3eHVAf4ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb918b5-442e-479b-964e-8d620f535106"
      },
      "source": [
        "# Save to Gdrive:\n",
        "# !rsync -avhr {dataset_dir} {backup_dir} --delete-during \n",
        "!rsync -avhr '/content/SemanticDroneDataset/' {dataset_dir} --delete-during"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sending incremental file list\n",
            "analise/overall_metrics_table.csv\n",
            "\n",
            "sent 31.99K bytes  received 133 bytes  21.41K bytes/sec\n",
            "total size is 3.71G  speedup is 115,397.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dbi-wU11a2G"
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "def resize(path, interp_type = cv2.INTER_NEAREST, dimsize = (960, 640), ext='.png'):\n",
        "  for filename in glob.glob(path+ '/*'+ext): #path of raw images\n",
        "    print(filename)\n",
        "    img = cv2.imread(filename)\n",
        "    res = cv2.resize(img, dsize=dimsize, interpolation=interp_type)\n",
        "    cv2.imwrite(filename, res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIQYAItq3aRm"
      },
      "source": [
        "# resize(\"/content/SemanticDroneDataset/images\", interp_type = cv2.INTER_CUBIC, dimsize = (960, 640), ext='.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4vKXUyN3wod"
      },
      "source": [
        "# resize('/content/SemanticDroneDataset/gt/label_images', interp_type = cv2.INTER_NEAREST, dimsize = (960, 640), ext='.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-yyB040sfHU"
      },
      "source": [
        "#Includes and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ9QguZM16El",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7edcc6-4465-43c9-ecf0-68f2ae516e6f"
      },
      "source": [
        "!pip install --upgrade line_profiler progressbar2 segmentation-models keras_applications"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting line_profiler\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/84/922000ff9798c58a95e701d602aa24f98b55bc52039cda4e452c2f879bdb/line_profiler-3.3.0-cp37-cp37m-manylinux2010_x86_64.whl (63kB)\n",
            "\r\u001b[K     |                          | 10kB 11.5MB/s eta 0:00:01\r\u001b[K     |                     | 20kB 15.8MB/s eta 0:00:01\r\u001b[K     |                | 30kB 11.6MB/s eta 0:00:01\r\u001b[K     |           | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |      | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     | | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     || 71kB 3.6MB/s \n",
            "\u001b[?25hCollecting progressbar2\n",
            "  Downloading https://files.pythonhosted.org/packages/25/8c/d28cd70b6e0b870a2d2a151bdbecf4c678199d31731edb44fc8035d3bb6d/progressbar2-3.53.1-py2.py3-none-any.whl\n",
            "Collecting segmentation-models\n",
            "  Downloading https://files.pythonhosted.org/packages/da/b9/4a183518c21689a56b834eaaa45cad242d9ec09a4360b5b10139f23c63f4/segmentation_models-1.0.1-py3-none-any.whl\n",
            "Collecting keras_applications\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     || 51kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: IPython>=0.13; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from line_profiler) (5.5.0)\n",
            "Requirement already satisfied, skipping upgrade: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2) (2.5.6)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from progressbar2) (1.15.0)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (1.0.18)\n",
            "Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (0.7.5)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (5.0.5)\n",
            "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (4.8.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=0.13; python_version >= \"3.7\"->line_profiler) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->IPython>=0.13; python_version >= \"3.7\"->line_profiler) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->IPython>=0.13; python_version >= \"3.7\"->line_profiler) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.10.0)\n",
            "Installing collected packages: line-profiler, progressbar2, keras-applications, efficientnet, image-classifiers, segmentation-models\n",
            "  Found existing installation: progressbar2 3.38.0\n",
            "    Uninstalling progressbar2-3.38.0:\n",
            "      Successfully uninstalled progressbar2-3.38.0\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 line-profiler-3.3.0 progressbar2-3.53.1 segmentation-models-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcBduoKnqf9x",
        "outputId": "96a763a3-4312-4e0d-9e86-1f79a40415d2"
      },
      "source": [
        "%env SM_FRAMEWORK=tf.keras\n",
        "%cd /content/SemanticDroneDataset/\n",
        "%tensorflow_version 2.x\n",
        "%load_ext autoreload\n",
        "%load_ext line_profiler\n",
        "# %load_ext line_profiler\n",
        "%autoreload 2\n",
        "\n",
        "# !git clone https://github.com/bonlime/keras-deeplab-v3-plus.git\n",
        "\n",
        "from matplotlib import rcParams\n",
        "from matplotlib.colors import LogNorm\n",
        "from PIL import Image\n",
        "from scipy import stats\n",
        "from scipy import signal\n",
        "from scipy import ndimage\n",
        "from matplotlib import cm\n",
        "from operator import itemgetter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "\n",
        "import segmentation_models as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import os\n",
        "import progressbar\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as et\n",
        "import cv2\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "\n",
        "sys.path.insert(1, '/content/SemanticDroneDataset/code')\n",
        "sys.path.insert(1, '/content/SemanticDroneDataset/keras-deeplab-v3-plus')\n",
        "from model import Deeplabv3\n",
        "\n",
        "from basefunctions import *\n",
        "# Load images and ground truth.\n",
        "#X_full, img_names = generate_training_var()\n",
        "#X_full_norm, _ = generate_training_var(True)\n",
        "#Y_full, Pixels_per_class = generate_onehot_gt()\n",
        "# Names of attributes.\n",
        "atributes_names = ['mean', 'standard_deviation', 'skewness', 'kurtosis']\n",
        "# Matplotlib style\n",
        "matplotlib.rcParams[\"font.family\"] = \"Dejavu Serif\"\n",
        "plt.style.use(['seaborn-colorblind']) \n",
        "plt.rcParams[\"figure.figsize\"] = (20, 30)\n",
        "plt.rcParams['font.size'] = 14\n",
        "plt.rcParams['axes.linewidth'] = 2\n",
        "\n",
        "# try:\n",
        "#   device_name = os.environ['COLAB_TPU_ADDR']\n",
        "#   TPU_ADDRESS = 'grpc://' + device_name\n",
        "#   print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "#   resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_ADDRESS)\n",
        "#   tf.config.experimental_connect_to_cluster(resolver) \n",
        "#   tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(resolver)\n",
        "# except:\n",
        "#   pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: SM_FRAMEWORK=tf.keras\n",
            "/content/SemanticDroneDataset\n",
            "Segmentation Models: using `tf.keras` framework.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmwL57I2shuP"
      },
      "source": [
        "#Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgAaMJ8s1C8h"
      },
      "source": [
        "### Number of images per classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idWzVfVsCL6P"
      },
      "source": [
        "# 389.xml EXCLUDO, POIS ARQUIVO EST VAZIO !!!!!!!!!\n",
        "!rm '/content/SemanticDroneDataset/gt/label_me_xml/389.xml'\n",
        "\n",
        "path = '/content/SemanticDroneDataset/gt/label_me_xml/'\n",
        "main_list = []\n",
        "\n",
        "# Iterate over all .xml files\n",
        "for filename in os.listdir(path):\n",
        "  if not filename.endswith('.xml'):\n",
        "    continue\n",
        "  fullname = path+filename\n",
        "  iteration_list = parse_XML(fullname,[\"object\",\"name\"])\n",
        "  main_list.extend(get_unique(iteration_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFFaii6wGQ2f"
      },
      "source": [
        "# Generate DF\n",
        "classes_list = np.array(main_list).flatten()\n",
        "classes_list = classes_list.flatten().flatten()\n",
        "classes_names, images_per_class = np.unique(classes_list, return_counts=True)\n",
        "\n",
        "classes_img_df = pd.DataFrame({'Name':classes_names, 'NumImages':images_per_class})\n",
        "classes_img_df = get_color_code(classes_img_df)\n",
        "classes_img_df.sort_values('NumImages', inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_4nF2_qMF6-"
      },
      "source": [
        "# Matplotlib style\n",
        "matplotlib.rcParams[\"font.family\"] = \"Dejavu Serif\"\n",
        "#plt.style.use(['seaborn-colorblind']) \n",
        "plt.style.use(['seaborn']) \n",
        "#plt.rcParams[\"figure.figsize\"] = (20, 30)\n",
        "plt.rcParams['font.size'] = 14\n",
        "plt.rcParams['axes.linewidth'] = 2\n",
        "\n",
        "# Create figure\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "x = np.arange(len(classes_names))\n",
        "ax1 = ax.bar(x, height = classes_img_df['NumImages'] )\n",
        "\n",
        "\n",
        "# Display bar value\n",
        "for i, v in enumerate(classes_img_df['NumImages']):\n",
        "    ax.text(i, v+5, str(v), va='center', ha='center', fontweight='bold')\n",
        "\n",
        "# Edit figure\n",
        "ax.set_title('Nmero de imagens que contm cada classe', fontsize='xx-large', pad=15)\n",
        "ax.set_ylabel('Nmero de imagens', fontsize='x-large',labelpad=10)\n",
        "ax.set_xlabel('Classes', fontsize='x-large',labelpad=10)\n",
        "ax.set_xticks(x) \n",
        "ax.set_xticklabels(classes_img_df['Name'], rotation=45, fontsize='large')\n",
        "fig.tight_layout()\n",
        "\n",
        "# Matplotlib general parameters  \n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['top'].set_visible(False)\n",
        "\n",
        "# Set color\n",
        "for bar, color in zip(ax1, classes_img_df['color']):\n",
        "  try:\n",
        "    #bar.set_color(np.array(color).astype(float))\n",
        "    bar.set_color('#9988DD') #'#3388BB', '#EECC55', '#88BB44', '#FFBBBB'\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "#Visualize and save\n",
        "plt.show\n",
        "if save_img:\n",
        "  #plt.savefig(f\"{analise_dir}/classe-hist-img.eps\")#, format=\"eps\")\n",
        "  plt.savefig( analise_dir + \"classe-hist-img\" + \".eps\", format=\"eps\") # TODO verificar se o comando t dando certo aqui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2wo37nrsUOB"
      },
      "source": [
        "## Feature Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XElL6UKF4yB"
      },
      "source": [
        "#def countplot_classes(Pixels_per_class, class_names):\n",
        "#https://matplotlib.org/stable/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py\n",
        "# Color palette\n",
        "plt.style.use(['seaborn']) \n",
        "\n",
        "# Generate data\n",
        "npixels_dataset = np.sum(Pixels_per_class)\n",
        "Pixels_per_class_p100 = 100*Pixels_per_class/npixels_dataset\n",
        "classes_df = pd.DataFrame( {'Name':class_names, 'NumbPixels':Pixels_per_class, 'Percentage':Pixels_per_class_p100})\n",
        "classes_df.sort_values('Percentage', inplace=True)\n",
        "\n",
        "# Create figure\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "x = np.arange(len(class_names) )\n",
        "ax1 = ax.bar(x, height = classes_df['Percentage'], color = 'b' )\n",
        "\n",
        "# Display bar value\n",
        "for i, v in enumerate(classes_df['Percentage']):\n",
        "    ax.text(i, v+1, str(round(v,1))+\"%\", va='center', ha='center', fontweight='bold')\n",
        "\n",
        "# Edit figure\n",
        "ax.set_title('Ocorrncia das classes a nvel de pixel', fontsize='xx-large', pad=15)\n",
        "ax.set_ylabel('Frequncia (%)', fontsize='x-large',labelpad=10)\n",
        "ax.set_xlabel('Classes', fontsize='x-large',labelpad=10)\n",
        "ax.set_xticks(x) \n",
        "ax.set_xticklabels(classes_df['Name'], rotation=45, fontsize='large')\n",
        "#ax.bar_label(ax1, padding=3)\n",
        "fig.tight_layout()\n",
        "plt.show\n",
        "print(np.size(classes_df['Name']))\n",
        "\n",
        "# Set color\n",
        "for bar in ax1:\n",
        "    bar.set_color('#9988DD') \n",
        "\n",
        "\n",
        "# Matplotlib general parameters  \n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['top'].set_visible(False)\n",
        "\n",
        "if save_img:\n",
        "  plt.savefig(f\"{analise_dir}/classe-hist-px.eps\")\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyZIOgO-B3Ha"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuRx8ZxwW1vE"
      },
      "source": [
        "# Create DF \n",
        "table_df, table_contents, pixelwise_stats = data_statistics_table(X_full_norm, img_names , act_index = 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI7RgS2XU31n"
      },
      "source": [
        "table_df, table_contents, pixelwise_stats = data_statistics_table(X_full_norm, img_names , act_index = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vNYNNlVVRs6"
      },
      "source": [
        "# Load DF from csv\n",
        "\n",
        "table_df = pd.read_csv('metadata/' + \"table_attributes_actv_0\" + '.csv')\n",
        "table_df.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqRgdxQT3rXC"
      },
      "source": [
        "plot_correlation_heatmap(\"table_attributes_actv_0\")\n",
        "plot_correlation_heatmap(\"table_attributes_actv_3\")\n",
        "plot_correlation_heatmap(\"table_attributes_actv_16\")\n",
        "plot_correlation_heatmap(\"table_attributes_actv_last\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ace2ZEpwVDOJ"
      },
      "source": [
        "# First layer activations (After ReLU):\n",
        "display_activation(X_full[0], act_index = 3)\n",
        "# Intermediate layer filters 'block3_sepconv1_act':\n",
        "display_activation(X_full[0], act_index = 16)\n",
        "# Last layer activations 'block14_sepconv2_act' (First 256 ones):\n",
        "display_activation(X_full[0], act_index = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqWLips8bSmy"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BaFrKCVN7Ub"
      },
      "source": [
        "### Definitions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VkErbbeEVny"
      },
      "source": [
        "def random_flipping(Img, Gt):\n",
        "  # Flip randomly the horizontal and/or vertical axis.\n",
        "  will_it_be_flipped = np.random.choice([0, 1], 2)\n",
        "  for i in [0, 1]:\n",
        "    if will_it_be_flipped[i]:\n",
        "      Img = np.flip(Img, axis = i)\n",
        "      Gt = np.flip(Gt, axis = i)\n",
        "  return Img, Gt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrmVpHgbEngr"
      },
      "source": [
        "def cut_window_randomly(Img, Gt, window_size ): # window_size = (vertical_size, horizontal_size)\n",
        "  imshape = Img.shape\n",
        "  assert window_size[0] <= imshape[0] and window_size[1] <= imshape[1]\n",
        "  max_position_start_vert = imshape[0] - window_size[0]\n",
        "  max_position_start_horiz = imshape[1] - window_size[1]\n",
        "  # Define window range to be extracted:\n",
        "  start_vert = np.random.randint(0, max_position_start_vert)\n",
        "  start_horiz = np.random.randint(0, max_position_start_horiz)\n",
        "  # Cut window:\n",
        "  Img = Img[ start_vert:(start_vert+window_size[0]), start_horiz:(start_horiz+window_size[1]) ]\n",
        "  Gt = Gt[ start_vert:(start_vert+window_size[0]), start_horiz:(start_horiz+window_size[1]) ]\n",
        "  return Img.astype(np.float32), Gt.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LmAjhmrErPh"
      },
      "source": [
        "def cut_window_and_rescale_randomly(Img, Gt, scaling_factor_min = -0.1, scaling_factor_max = 0.1, window_size = (320, 480)): \n",
        "  '''\n",
        "    Distort the image by a random scaling factor 'scale', which is in the range (scaling_factor_min, scaling_factor_max).  \n",
        "    The vertical dimension will be stretched by a factor (1+scale) and the horizontal dimension will be stretched by a factor (1-scale).\n",
        "  '''\n",
        "  imshape = Img.shape\n",
        "  assert window_size[0]*max(abs(scaling_factor_min), abs(scaling_factor_max) ) <= imshape[0] and max(abs(scaling_factor_min), abs(scaling_factor_max) ) <= imshape[1]\n",
        "  \n",
        "  scale = np.random.uniform(scaling_factor_min, scaling_factor_max ) # Generate scaling factor by a uniform distribution.\n",
        "  window_size_before_scaling = ( int(window_size[0]*(1+scale)), int(window_size[1]*(1-scale)) ) # Define the cutting area. This area will then be resized to the desired size 'window_size'.\n",
        "  # print(window_size_before_scaling)\n",
        "  Img, Gt = cut_window_randomly(Img, Gt, window_size_before_scaling ) # Cut a random area of the input image with size 'window_size_before_scaling'.\n",
        "  Img, Gt = resize_window(Img, Gt, window_size)\n",
        "  return Img.astype(np.float32), Gt.astype(np.float32)\n",
        "\n",
        "def resize_window(Img, Gt, window_size = (320,480)):\n",
        "  Img = cv2.resize(Img.astype(np.uint8), dsize=(window_size[1], window_size[0]), interpolation=cv2.INTER_CUBIC ).astype(np.float32) # Resize enlarged image to the desired window size. This creates a stretched (or compressed) image.\n",
        "  Gt =  cv2.resize(Gt.astype(np.uint8), dsize=(window_size[1], window_size[0]), interpolation=cv2.INTER_NEAREST).astype(np.float32) # Do the same thing to the ground truth. Important to use cv2.INTER_NEAREST to maitain the values of the pixels in the Gt.\n",
        "  return Img, Gt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0OuUskyEvLY"
      },
      "source": [
        "def random_motion_blur(Img, filter_size_min = 3, filter_size_max = 7, augmentation_probability = 0.5): # The size of the filter is proportional to the blur intensity.\n",
        "  will_blur_be_added = np.random.choice([0, 1], p = [1-augmentation_probability, augmentation_probability]) # Generate a binary RV with P(1) = p and P(0) = 1-p.\n",
        "  if will_blur_be_added: # If blur should be added in one or both axes:\n",
        "    which_blur_direction = np.random.choice(['horiz', 'vert', 'diag_pri', 'diag_sec'])\n",
        "    filter_size = np.random.randint(filter_size_min, filter_size_max) # Set the filter size randomly in the range (3, filter_max_size).\n",
        "    if filter_size % 2 == 0:\n",
        "      filter_size += 1 # Make sure filter_size is odd.\n",
        "    # print(\"Motion blur filter size = %d.\" % filter_size)\n",
        "    \n",
        "    if which_blur_direction == 'vert': # If the filtering is to be added only in the Y axis.\n",
        "      # print(\"The vertical axis will be filtered.\")\n",
        "      filter = np.zeros((filter_size, filter_size)) # Initialize filter\n",
        "      filter[:, filter_size//2] = 1/filter_size\n",
        "    if which_blur_direction == 'horiz': # If the filtering is to be added only in the X axis.\n",
        "      # print(\"The horizontal axis will be filtered.\")\n",
        "      filter = np.zeros((filter_size, filter_size)) # Initialize filter\n",
        "      filter[filter_size//2, :] = 1/filter_size\n",
        "    if which_blur_direction == 'diag_pri':\n",
        "      # print(\"The diagonal axis will be filtered.\")\n",
        "      filter = np.diagflat(np.ones(filter_size))*1/filter_size\n",
        "    if which_blur_direction == 'diag_sec':\n",
        "      # print(\"The second diagonal axis will be filtered.\")\n",
        "      filter = np.fliplr( np.diagflat(np.ones(filter_size)) )*1/filter_size\n",
        "    \n",
        "    print(filter)\n",
        "    for chan_ind in [0, 1, 2]: # Convolve every channel with the produced motion blur filter.\n",
        "      Img[:, :, chan_ind] = signal.fftconvolve(Img[:, :, chan_ind], filter, mode = 'same') \n",
        "  return Img.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oRf_e63EyX7"
      },
      "source": [
        "def modify_hsv_randomly(Img, std = 0.05): # Change Hue, Saturation and Brightness (HSV) randomly based on a normal RV with standard deviation = std*max_channel_value.\n",
        "  Img = ( cv2.cvtColor(Img, cv2.COLOR_RGB2HSV) ).astype(np.float32) # Convert RGB image to HSV domain.\n",
        "  rescale_vector = [360, 1, 255] # Maximum values for each HSV channel.\n",
        "  for hsv_ind in [0, 1, 2]: # Apply transformation to each channel individually.\n",
        "    rv = np.random.normal(loc = 0, scale = std)*rescale_vector[hsv_ind] # Generate noise value.\n",
        "    # print(hsv_ind, rv)\n",
        "    Img[:, :, hsv_ind] = Img[:, :, hsv_ind] + rv # Add to channel.\n",
        "    Img[:, :, hsv_ind] = np.clip(Img[:, :, hsv_ind], 0, rescale_vector[hsv_ind]) # Clip values bigger than the maximum channel value.\n",
        "  Img = ( cv2.cvtColor(Img, cv2.COLOR_HSV2RGB) ).astype(np.float32) # Convert image back to RGB domain.\n",
        "  return Img.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53iHyaI-E138"
      },
      "source": [
        "def standardize(Img):\n",
        "  desc = stats.describe(Img, axis = None)\n",
        "  Img = (Img - desc.mean )/desc.variance\n",
        "  return Img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOU1q_N_E469"
      },
      "source": [
        "# Source: https://www.programmersought.com/article/22264609506 . Had to fix some bugs.\n",
        "def rotate_and_crop_randomly(Img, Gt, angle_min = 0, angle_max = 359, crop = True):\n",
        "    assert isinstance(Img, np.ndarray) and isinstance(Gt, np.ndarray) and ( isinstance(angle_min + angle_max, int) or isinstance(angle_min + angle_max, float) )\n",
        "    assert Img.shape == Gt.shape\n",
        "    crop_image = lambda Img, x0, y0, w, h: Img[x0:x0+w, y0:y0+h, :]  # Define the cutting function and use it for subsequent cutting of black edges\n",
        "    w, h = Img.shape[:2]\n",
        "    # The period of the rotation angle is 360\n",
        "    angle = int( np.random.uniform(low = angle_min, high = angle_max) )\n",
        "    angle %= 360\n",
        "    # print(\"Rotation angle = %d degrees.\" % angle)\n",
        "    # Get the rotated image\n",
        "    Img = np.array( (Image.fromarray(Img.astype(np.uint8) )).rotate(angle, resample=Image.CUBIC, expand=False, center=None, translate=None, fillcolor=None) )\n",
        "    Gt = np.array( (Image.fromarray(Gt.astype(np.uint8) )).rotate(angle, resample=Image.NEAREST, expand=False, center=None, translate=None, fillcolor=None) )\n",
        "\n",
        "    # If you need to remove the black border\n",
        "    if crop:\n",
        "        # The equivalent period of the cutting angle is 180\n",
        "        angle_crop = angle % 180\n",
        "        if angle_crop > 90:\n",
        "            angle_crop = 180 - angle_crop\n",
        "        # Convert angle to radians\n",
        "        theta = angle_crop * np.pi / 180\n",
        "        # Calculate the aspect ratio\n",
        "        hw_ratio = float(h) / float(w)\n",
        "        # Calculate the numerator of the cropping side length coefficient\n",
        "        tan_theta = np.tan(theta)\n",
        "        numerator = np.cos(theta) + np.sin(theta) * np.tan(theta)\n",
        "\n",
        "        # Calculate the terms related to the aspect ratio in the denominator\n",
        "        r = hw_ratio if h > w else 1 / hw_ratio\n",
        "        # Calculate the denominator term\n",
        "        denominator = r * tan_theta + 1\n",
        "        # Final side length coefficient\n",
        "        crop_mult = numerator / denominator\n",
        "\n",
        "        # Get crop area\n",
        "        w_crop = int(crop_mult * w)\n",
        "        h_crop = int(crop_mult * h)\n",
        "        x0 = int((w - w_crop) / 2)\n",
        "        y0 = int((h - h_crop) / 2)\n",
        "        Img = crop_image(Img, x0, y0, w_crop, h_crop)\n",
        "        Gt = crop_image(Gt, x0, y0, w_crop, h_crop)\n",
        "    return Img.astype(np.float32), Gt.astype(np.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A-eXakKEdlJ"
      },
      "source": [
        "def load_img(img_name):\n",
        "  # print( str(img_name), images_path)\n",
        "  if not isinstance(img_name, str):\n",
        "    img_name = str(img_name, \"utf-8\")\n",
        "  Img = np.asarray( image.load_img(images_path + str(img_name) + '.jpg'), dtype=np.float32 )\n",
        "  # Retrieve ground truth\n",
        "  Gt_RGB = np.asarray( image.img_to_array( image.load_img(gt_labels_path + img_name + '.png') ),  dtype=np.float32)\n",
        "  return Img, Gt_RGB\n",
        "\n",
        "def augment_img(Img, Gt_RGB, n_returns = 1, set_type='train'):\n",
        "  # \n",
        "  if not isinstance(set_type, str):\n",
        "    set_type = str(set_type, \"utf-8\")\n",
        "  assert set_type == 'train' or set_type == 'val'\n",
        "  # images_path, gt_labels_path, class_colors are global variables.\n",
        "  wsize = (320,480)\n",
        "  Img_list = []\n",
        "  Gt_RGB_list = []\n",
        "  for i in range(n_returns):\n",
        "    # Apply transforms:\n",
        "    # Rotate image before transforms.\n",
        "    Img_aux = Img\n",
        "    Gt_RGB_aux = Gt_RGB\n",
        "    if set_type=='train':\n",
        "      # Img_aux, Gt_RGB_aux = rotate_and_crop_randomly(Img_aux, Gt_RGB_aux, angle_min = 0, angle_max = 359, crop = True)\n",
        "      # Img_aux, Gt_RGB_aux = cut_window_and_rescale_randomly(Img_aux, Gt_RGB_aux, window_size = wsize)\n",
        "      \n",
        "      Img_aux, Gt_RGB_aux = resize_window(Img_aux, Gt_RGB_aux, window_size = wsize) # \n",
        "      Img_aux, Gt_RGB_aux = random_flipping(Img_aux, Gt_RGB_aux)\n",
        "      Img_aux = modify_hsv_randomly(Img_aux)\n",
        "    elif set_type=='val':\n",
        "      Img_aux, Gt_RGB_aux = resize_window(Img_aux, Gt_RGB_aux, window_size = wsize)\n",
        "    # Standardize 0 mean 1 variance\n",
        "    Img_aux = standardize(Img_aux)\n",
        "    Img_list.append(Img_aux.astype(np.float32))\n",
        "    Gt_RGB_list.append(Gt_RGB_aux)\n",
        "\n",
        "  Img_list = np.array(Img_list)\n",
        "  Gt_RGB_list = np.array(Gt_RGB_list)\n",
        "\n",
        "  # print(Img_list.shape, Gt_RGB_list.shape)\n",
        "  # Convert GT to one-hot:\n",
        "  Y = np.zeros( ( Gt_RGB_list.shape[0], Gt_RGB_list.shape[1], Gt_RGB_list.shape[2], nclasses ), dtype = np.float32) # Shape = (nimages, nclasses, npix_vert, npix_horiz ). We substitute the 3 RGB channels for a one-hot vector of dimensions 'nclasses'.\n",
        "  for class_idx, class_color in enumerate(class_colors):\n",
        "    coord_pixels_of_a_class = np.logical_and( np.logical_and( ( Gt_RGB_list[:, :, :, 0] == class_color[0] ) ,\n",
        "                                                             Gt_RGB_list[:, :, :, 1] == class_color[1] ),  Gt_RGB_list[:, :, :, 2] == class_color[2] ) # Retrieve pixel coordinates where class 'class_color' is present.\n",
        "    # print(coord_pixels_of_a_class.shape, Y[:, :, :, class_idx].shape)\n",
        "    Y[:, :, :, class_idx][coord_pixels_of_a_class.nonzero()] = 1\n",
        "  return Img_list, Y.astype(np.float32), Gt_RGB_list.astype(np.uint8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mynDC0qWODgr"
      },
      "source": [
        "### Test data augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2TPLrhvkBPK"
      },
      "source": [
        "# frame1.axes.get_xaxis().set_visible(False)\n",
        "# frame1.axes.get_yaxis().set_visible(False)\n",
        "# set_title(\"Image, origin 'upper'\")X, Y, Y_RGB = load_img_and_augment('original/040')\n",
        "# X_og = np.array( Image.open(images_path + 'original/040' + '.jpg').convert('RGB') )\n",
        "# plt.imshow( X_og)\n",
        "# plt.imshow(Y_RGB.astype(np.uint8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuH2YHWWOMYW"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjkWOWSMegpe"
      },
      "source": [
        "## Loss function def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGTmD7WG7Wb-",
        "outputId": "25fa147f-6573-4ebf-ac6d-0cca0374225c"
      },
      "source": [
        "# # ALPHA COMPUTATION\n",
        "\n",
        "# # Frequencia das classes por pixel\n",
        "# # Retirei os dados do grafico do relatorio\n",
        "# # Usei a ordem das classes do .csv\n",
        "\n",
        "# # TODO verificar se a ordem das sadas da rede  a mesma\n",
        "# class_list = np.array(\n",
        "#               ['unlabeled', 'paved-area', 'dirt', 'grass', 'gravel',\\\n",
        "#               'water', 'rocks', 'pool', 'vegetation', 'roof',\\\n",
        "#               'wall', 'window','door', 'fence', 'fence-pole',\\\n",
        "#               'person', 'dog', 'car', 'bicycle', 'tree',\\\n",
        "#               'bald-tree', 'ar-marker', 'obstacle']\n",
        "# )\n",
        "\n",
        "\n",
        "# dog e door tem porcentagem 0\n",
        "# conflicting nao foi contabilizado\n",
        "\n",
        "freq_list = np.array([[0.001, 0.378, 0.032, 0.20, 0.073,\\\n",
        "             0.022, 0.007, 0.006, 0.071, 0.074,\\\n",
        "             0.027, 0.006, 0.0, 0.01, 0.001,\\\n",
        "             0.011, 0.0, 0.008, 0.002, 0.021,\\\n",
        "             0.013, 0.002, 0.035]]).T\n",
        "\n",
        "freq_list_argsort = np.flip( np.argsort(freq_list.squeeze()) )\n",
        "\n",
        "freq_list[(freq_list==0).nonzero()] = 0.001\n",
        "\n",
        "alpha = 1/np.power(freq_list,1/2)\n",
        "alpha = (alpha)/np.sum(alpha)\n",
        "alpha = np.reshape(alpha, (1,1,1,23) )\n",
        "print(alpha)\n",
        "\n",
        "freq_list_argsort"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[0.1075141  0.00552993 0.01900599 0.00760239 0.01258357 0.02292208\n",
            "    0.04063651 0.04389245 0.01275958 0.01249826 0.0206911  0.04389245\n",
            "    0.1075141  0.03399894 0.1075141  0.03241672 0.1075141  0.03801197\n",
            "    0.07602395 0.0234615  0.02981905 0.07602395 0.0181732 ]]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  3,  9,  4,  8, 22,  2, 10,  5, 19, 20, 15, 13, 17,  6, 11,  7,\n",
              "       21, 18, 14,  0, 12, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMFY6tDIej8X"
      },
      "source": [
        "# FOCAL LOSS DEFINITION\n",
        "def focal_loss(alpha, gamma = 2.0):\n",
        "  alpha = tf.convert_to_tensor(alpha, dtype=tf.float32)\n",
        "\n",
        "  def categorical_focal_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    :param y_true: A tensor of the same shape as `y_pred`\n",
        "    :param y_pred: A tensor resulting from a softmax\n",
        "    :return: Output tensor.\n",
        "    \"\"\"\n",
        "    tf.cast(y_true, tf.float32)\n",
        "    tf.cast(y_pred, tf.float32)\n",
        "    # Clip the prediction value to prevent NaN's and Inf's\n",
        "    epsilon = tf.keras.backend.epsilon()\n",
        "    y_pred = tf.keras.backend.clip(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "    # Calculate Cross Entropy\n",
        "    cross_entropy = tf.multiply(-y_true, tf.math.log(y_pred))\n",
        "    # Calculate Focal Loss\n",
        "    loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n",
        "\n",
        "    # Compute mean loss in mini_batch\n",
        "    cost = tf.reduce_mean(loss)\n",
        "    # tf.keras.backend.print_tensor(cost, message='losses')\n",
        "    return cost\n",
        "  return categorical_focal_loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZmHHblaP-mp"
      },
      "source": [
        "## Unet model def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOPtNHeLmz3L"
      },
      "source": [
        "\n",
        "# def unet_model(img_size=(320,480,3), num_classes=23):\n",
        "#     filter_size = 7\n",
        "#     inputs = Input(shape=img_size)\n",
        "\n",
        "#     ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "#     # Entry block\n",
        "#     x = Conv2D(32, filter_size, strides=2, padding=\"same\")(inputs)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Activation(\"relu\")(x)\n",
        "\n",
        "#     previous_block_activation = x  # Set aside residual\n",
        "\n",
        "#     # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "#     for filters in [64, 128, 256]:\n",
        "#         x = Activation(\"relu\")(x)\n",
        "#         x = SeparableConv2D(filters, filter_size, padding=\"same\")(x)\n",
        "#         x = BatchNormalization()(x)\n",
        "\n",
        "#         x = Activation(\"relu\")(x)\n",
        "#         x = SeparableConv2D(filters, filter_size, padding=\"same\")(x)\n",
        "#         x = BatchNormalization()(x)\n",
        "\n",
        "#         x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "#         # Project residual\n",
        "#         residual = Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "#             previous_block_activation\n",
        "#         )\n",
        "#         x = add([x, residual])  # Add back residual\n",
        "#         previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "#     ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "#     for filters in [256, 128, 64, 32]:\n",
        "#         x = Activation(\"relu\")(x)\n",
        "#         x = Conv2DTranspose(filters, filter_size, padding=\"same\")(x)\n",
        "#         x = BatchNormalization()(x)\n",
        "\n",
        "#         x = Activation(\"relu\")(x)\n",
        "#         x = Conv2DTranspose(filters, filter_size, padding=\"same\")(x)\n",
        "#         x = BatchNormalization()(x)\n",
        "\n",
        "#         x = UpSampling2D(2)(x)\n",
        "\n",
        "#         # Project residual\n",
        "#         residual = UpSampling2D(2)(previous_block_activation)\n",
        "#         residual = Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "#         x = add([x, residual])  # Add back residual\n",
        "#         previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "#     # Add a per-pixel classification layer\n",
        "#     outputs = Conv2D(num_classes, filter_size, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "#     # Define the model\n",
        "#     model = Model(inputs, outputs)\n",
        "#     model.model_name = \"unet\"\n",
        "#     # adam = Adam(learning_rate = 1e-4)\n",
        "#     # model.compile(optimizer = adam, loss=focal_loss(alpha) )\n",
        "#     return model\n",
        "\n",
        "\n",
        "\n",
        "def unet_model(img_size=(320,480,3), num_classes=23):\n",
        "    filter_size = 3\n",
        "    inputs = Input(shape=img_size)\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = Conv2D(64, filter_size, strides=2, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [128, 256, 512]:\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(filters, filter_size, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(filters, filter_size, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    for filters in [512, 256, 128, 64]:\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2DTranspose(filters, filter_size, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = Conv2DTranspose(filters, filter_size, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = UpSampling2D(2)(previous_block_activation)\n",
        "        residual = Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = Conv2D(num_classes, filter_size, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs, outputs)\n",
        "    model.model_name = \"unet\"\n",
        "    # adam = Adam(learning_rate = 1e-4)\n",
        "    # model.compile(optimizer = adam, loss=focal_loss(alpha) )\n",
        "    return model\n",
        "\n",
        "\n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "\n",
        "# # Free up RAM in case the model definition cells were run multiple times\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lntgQ-vlQdH1"
      },
      "source": [
        "## Perform data augmentation def"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpP1AdVWbOfh"
      },
      "source": [
        "def segmentation_generator(img_set, batch_size, batches_per_img, data_set_type):\n",
        "  # number_of_loads = int( np.ceil( len(img_set)/bulk_size ) )\n",
        "  while True:\n",
        "    for img in img_set:\n",
        "      Img, Gt_RGB = load_img(img)\n",
        "      for i in range(batches_per_img):\n",
        "        Img_list, Y_list, _ = augment_img(Img, Gt_RGB, n_returns=batch_size, set_type=data_set_type)\n",
        "        yield Img_list, Y_list\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs8zLrEWQLO0"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEcfATfHWP4n"
      },
      "source": [
        "### Train Load Save Model defs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crGwS0zEYreR"
      },
      "source": [
        "def train_model(train_index = np.arange(0, 250, 1), validation_index = np.arange(250, 300, 1), n_epochs = 40, model_name=\"trained_model\", model = None, initial_epoch = 0):\n",
        "  img_path = working_dir + 'images/*.jpg'\n",
        "  gt_path = working_dir + 'gt/label_images/*.png'\n",
        "  img_set = [imname.split('/')[-1].split('.')[0] for imname in glob.glob(img_path)]\n",
        "  img_set = sorted(img_set, key=lambda x: int(x)) \n",
        "  train_set = itemgetter(*train_index)(img_set)\n",
        "  val_set = itemgetter(*validation_index)(img_set)\n",
        "\n",
        "  batch_size = 5\n",
        "  batches_per_img = 1\n",
        "  img_shape = (None, 320, 480, 3)\n",
        "  gt_shape = (None, 320, 480, 23)\n",
        "  print('Train: ' +  str(train_set) )\n",
        "  print('Validation: ' + str(val_set) )\n",
        "\n",
        "  # es = tf.keras.callbacks.EarlyStopping(\n",
        "  #       monitor=\"val_loss\",\n",
        "  #       min_delta=0,\n",
        "  #       patience=5,\n",
        "  #       verbose=0,\n",
        "  #       baseline=None,\n",
        "  #       restore_best_weights=True,\n",
        "  #     )\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=dataset_dir + 'trained_models/' + model_name,\n",
        "    monitor='val_accuracy', verbose=1, save_best_only=True,\n",
        "    save_weights_only=False, mode='auto', save_freq='epoch'\n",
        "  )\n",
        "\n",
        "  try:\n",
        "    train_data = tf.data.Dataset.from_generator( segmentation_generator, args = [ train_set, batch_size, batches_per_img, 'train' ], output_signature=(\n",
        "                  tf.TensorSpec(shape=img_shape, dtype=tf.float32), tf.TensorSpec(shape=gt_shape, dtype=tf.float32) ) )\n",
        "    val_data = tf.data.Dataset.from_generator( segmentation_generator, args = [ val_set, 1, 1, 'val' ], output_signature=(\n",
        "                  tf.TensorSpec(shape=img_shape, dtype=tf.float32), tf.TensorSpec(shape=gt_shape, dtype=tf.float32) ) )\n",
        "    if model is None:\n",
        "      # model = unet_model()\n",
        "      # model = sm.Unet('resnet', classes=23, activation='softmax', encoder_weights='imagenet')\n",
        "      # model = sm.Unet('inceptionv3', classes=23, activation='softmax', encoder_weights='imagenet')\n",
        "      # model = sm.Unet('resnet50', classes=23, activation='softmax', encoder_weights='imagenet')\n",
        "      model = Deeplabv3(weights='cityscapes', input_shape=(img_shape[1], img_shape[2], img_shape[3] ), classes=23, activation='softmax', backbone='xception')\n",
        "      # model.compile(optimizer = Adam(learning_rate = 1e-3), loss=focal_loss(alpha), metrics=['accuracy'] )\n",
        "      # cce = tf.keras.losses.CategoricalCrossentropy(\n",
        "      #         from_logits=False,\n",
        "      #         label_smoothing=0,\n",
        "      #         reduction=\"auto\",\n",
        "      #         name=\"categorical_crossentropy\",\n",
        "      #     )\n",
        "      # model.compile(optimizer = Adam(learning_rate = 1e-3), loss=cce, metrics=['accuracy'] )\n",
        "      model.compile(optimizer = Adam(learning_rate = 1e-3), loss=focal_loss(alpha, 2), metrics=['accuracy'] )\n",
        "    model.summary()\n",
        "    model.fit(train_data,\n",
        "              epochs=n_epochs,\n",
        "              steps_per_epoch=len(train_set)*batches_per_img,\n",
        "              validation_data=val_data, \n",
        "              validation_steps=len(val_set),\n",
        "              workers = 4, use_multiprocessing=True,\n",
        "              callbacks=[model_checkpoint_callback],\n",
        "              initial_epoch=initial_epoch)\n",
        "      # history = model.fit(segmentation_generator(train_set, batch_size, batches_per_img, data_set_type='train'), epochs = n_epochs, \n",
        "      #             steps_per_epoch = len(train_set)*batches_per_img, # Ceil is used to get the last patches from the image.\n",
        "      #             validation_data = segmentation_generator(val_set, 1, 1, data_set_type='val'), \n",
        "      #             validation_steps = len(val_set), \n",
        "      #             workers = 4, use_multiprocessing=True, callbacks=[es] )\n",
        "    return model\n",
        "  except KeyboardInterrupt:\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9YvylrxB1Zd"
      },
      "source": [
        "def save_model(model, model_name, save_to_drive=True):\n",
        "  assert isinstance(model_name, str)\n",
        "  model.save(working_dir + 'trained_models/' + model_name )\n",
        "  if save_to_drive:\n",
        "    model.save(dataset_dir + 'trained_models/' + model_name )\n",
        "\n",
        "def load_model(model_name):\n",
        "  assert isinstance(model_name, str)\n",
        "  focal_loss_instance = focal_loss(alpha, 2)\n",
        "  print(working_dir + 'trained_models/' + model_name)\n",
        "  model = tf.keras.models.load_model(working_dir + 'trained_models/' + model_name, custom_objects={\"categorical_focal_loss\":focal_loss_instance})\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5x4Y05OWiTP"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hRu1R19iW7c"
      },
      "source": [
        "LOAD_WEIGHTS = True\n",
        "model_to_load = 'trained_model_060621_deeplabv3_nocut'\n",
        "name_to_save = 'trained_model_060621_deeplabv3_nocut'\n",
        "last_train_epoch = 0     \n",
        "total_epochs = 50             \n",
        "\n",
        "K.backend.clear_session()\n",
        "\n",
        "if LOAD_WEIGHTS:\n",
        "  loaded_model = load_model(model_to_load)\n",
        "  model_trained = train_model(model_name=name_to_save, model=loaded_model, initial_epoch=0, n_epochs=total_epochs) \n",
        "else:  \n",
        "  model_trained = train_model(model_name=name_to_save, initial_epoch=last_train_epoch, n_epochs=total_epochs) \n",
        "\n",
        "\n",
        "# NOTES\n",
        "# 08/Jun Debora:      'trained_model_060621_deeplabv3_nocut'       50/50         val_accuracy: 0.59150\n",
        "\n",
        "\n",
        "# model_trained = train_model(train_index=[0,1], validation_index=[2,3])\n",
        "# model_trained = train_model(model_name=\"trained_model_060621_deeplabv3\", model = None) # It was in the 16th epoch\n",
        "# model_trained = train_model(model_name=\"trained_model_070621_deeplabv3_cutting\", model = model_trained, initial_epoch=39, n_epochs=80) # It was in the 16th epoch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNaWZnb4aBMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adefe451-85e6-4e96-a73c-fc6023b5917b"
      },
      "source": [
        "# save_model(model_trained, 'trained_model_030621')\n",
        "model_trained = load_model('trained_model_060621_deeplabv3_nocut')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SemanticDroneDataset/trained_models/trained_model_060621_deeplabv3_nocut\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJn-RrZFS8P6"
      },
      "source": [
        "## Show detections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR2GXB39eA49"
      },
      "source": [
        "def detect_and_analyse(img_name, model_trained, return_images = False):\n",
        "  \n",
        "  Img, Gt = load_img(img_name)\n",
        "  Img, Y, Gt = augment_img(Img, Gt, 1, 'val')\n",
        "  n_pix = Img.shape[1]*Img.shape[2]\n",
        "  Y = np.squeeze(Y)\n",
        "  Y_pred = model_trained.predict(Img)\n",
        "  Y_pred_onehot = tf.squeeze( tf.one_hot(tf.argmax(Y_pred, axis=-1), Y.shape[-1]) )\n",
        "  Y_pred_argmax = np.argmax(Y_pred_onehot, axis=-1)\n",
        "  Y_pred_rgb = np.zeros( (Y.shape[0], Y.shape[1], 3), dtype = np.uint8 ) # Shape = (nimages, nclasses, npix_vert, npix_horiz ). We substitute the 3 RGB channels for a one-hot vector of dimensions 'nclasses'.\n",
        "  for class_idx, class_color in enumerate(class_colors):\n",
        "    coord_pixels_of_a_class = (Y_pred_argmax == class_idx).nonzero()\n",
        "    Y_pred_rgb[coord_pixels_of_a_class] = class_color\n",
        "  \n",
        "  Y_pred_argmax_flat = (Y_pred_argmax).flatten()\n",
        "  Y_argmax_flat = ( np.argmax(Y, axis=-1) ).flatten()\n",
        "  confused_matrix = confusion_matrix(Y_argmax_flat, Y_pred_argmax_flat, labels = np.arange(0, 23))\n",
        "  \n",
        "  mIOU = np.sum( np.logical_and(Y, Y_pred_onehot), axis = (0, 1) )/np.sum( np.logical_or(Y, Y_pred_onehot), axis = (0, 1) )\n",
        "  if return_images:\n",
        "    return Img, Gt, Y_pred_rgb, confused_matrix, mIOU\n",
        "  else:\n",
        "    return confused_matrix, mIOU\n",
        "\n",
        "def multiple_images_metrics(img_index = np.arange(300, 400), model_name = \"trained_model_060621_deeplabv3_nocut\", model_trained = None):\n",
        "  if model_trained is None:\n",
        "    model_trained = load_model(model_name)\n",
        "  img_path = working_dir + 'images/*.jpg'\n",
        "  img_set = [imname.split('/')[-1].split('.')[0] for imname in glob.glob(img_path)]\n",
        "  img_set = np.array(sorted(img_set, key=lambda x: int(x)))[img_index]\n",
        "  confusion_matrix = []\n",
        "  mIOU_vector = []\n",
        "  # with Parallel(n_jobs = 4, verbose=10, backend='threading') as parfor:\n",
        "  #   results = parfor( delayed(detect_and_analyse)(img_set[i], model_name = model_name, return_images = False) for i in range(len(img_set) ) )\n",
        "  for i in range(len(img_set) ):\n",
        "    print(\"Processing Image \" + img_set[i])\n",
        "    confused_matrix, mIOU = detect_and_analyse(img_set[i], model_trained, return_images = False)\n",
        "    confusion_matrix.append( confused_matrix )\n",
        "    mIOU_vector.append(mIOU)\n",
        "  avg_confusion_matrix = np.sum( np.array(confusion_matrix), axis = 0)\n",
        "  avg_confusion_matrix = avg_confusion_matrix/np.sum(avg_confusion_matrix+1e-9, axis = 1).reshape(-1,1)\n",
        "  mIOU_vector = np.array(mIOU_vector)\n",
        "  mIOU_vector_aux = np.copy(mIOU_vector)\n",
        "  mIOU_vector_aux[np.isnan( mIOU_vector ) ] = 0\n",
        "  avg_mIOU_vector = np.sum(mIOU_vector_aux, axis = 0)/np.count_nonzero( np.logical_not( np.isnan(mIOU_vector) ), axis = 0)\n",
        "  return avg_confusion_matrix, avg_mIOU_vector\n",
        "\n",
        "def plot_confusion_matrix(confused_matrix, permute_matrix = freq_list_argsort, list_of_classes = class_names, figname = None):\n",
        "  list_of_classes = np.array(list_of_classes)[permute_matrix]\n",
        "  print(list_of_classes.shape)\n",
        "  confused_matrix = confused_matrix[:, permute_matrix][permute_matrix, :]\n",
        "  confused_matrix[confused_matrix < 1e-5] = np.nan\n",
        "  print(confused_matrix)\n",
        "  conf_df = pd.DataFrame(confused_matrix, index = list_of_classes, columns = list_of_classes)\n",
        "  fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (35,10))\n",
        "  sns.heatmap(conf_df, annot=True, linewidths=1, linecolor='black', cmap=sns.color_palette(\"rocket_r\", as_cmap=True), norm=LogNorm())\n",
        "  # sns.heatmap(conf_df, annot=True, linewidths=1, linecolor='black', cmap=sns.color_palette(\"rocket_r\", as_cmap=True))\n",
        "  if not figname is None:\n",
        "    plt.savefig( analise_dir + figname + \".eps\", format=\"eps\", bbox_inches='tight') # TODO verificar se o comando t dando certo aqui\n",
        "  #\n",
        "\n",
        "def metrics_from_confusion(confusion, save_name = None):\n",
        "  non_diag_mask = 1 - np.eye( confusion.shape[1])\n",
        "  confusion_aux = np.copy(confusion)\n",
        "  confusion_aux[np.isnan(confusion_aux)] = 0\n",
        "  sum_confusion = np.sum(confusion_aux, axis = 1)\n",
        "  sum_confusion_vertical = np.sum(confusion_aux, axis = 0)\n",
        "  recall_class = confusion_aux.diagonal()/sum_confusion\n",
        "  precision_class = confusion_aux.diagonal()/sum_confusion_vertical\n",
        "  \n",
        "  prec_nan_idx = np.isnan(precision_class)\n",
        "  pclass_aux = np.copy(precision_class)\n",
        "  pclass_aux = np.delete(pclass_aux, prec_nan_idx)\n",
        "  freq_list_precision = np.delete(freq_list.squeeze(), prec_nan_idx)\n",
        "\n",
        "  print(prec_nan_idx, pclass_aux.shape, pclass_aux)\n",
        "  \n",
        "  false_negative_rate_class = np.sum( confusion_aux*non_diag_mask, axis = 1 )/sum_confusion\n",
        "  recall = np.average(recall_class, weights = freq_list.squeeze() )\n",
        "  false_negative_rate = np.average(false_negative_rate_class, weights = freq_list.squeeze() )\n",
        "  precision = np.average(pclass_aux, weights = freq_list_precision )\n",
        "  \n",
        "  if not save_name is None:\n",
        "    with open(analise_dir + save_name + '.pkl', 'wb') as f:\n",
        "      pickle.dump(recall, f)\n",
        "      pickle.dump(precision, f)\n",
        "      pickle.dump(false_negative_rate, f)\n",
        "      pickle.dump(recall_class, f)\n",
        "      pickle.dump(precision_class, f)\n",
        "      pickle.dump(false_negative_rate_class, f)\n",
        "  return recall, precision, false_negative_rate, recall_class, precision_class, false_negative_rate_class\n",
        "\n",
        "def load_metrics_from_confusion(load_name):\n",
        "  print(analise_dir + load_name + '.pkl', 'rb')\n",
        "  with open(analise_dir + load_name + '.pkl', 'rb') as f:\n",
        "    recall = pickle.load(f)\n",
        "    precision = pickle.load(f)\n",
        "    false_negative_rate = pickle.load(f)\n",
        "    recall_class = pickle.load(f)\n",
        "    precision_class =  pickle.load(f)\n",
        "    false_negative_rate_class = pickle.load(f)\n",
        "  return recall, precision, false_negative_rate, recall_class, precision_class, false_negative_rate_class  \n",
        "\n",
        "def metrics_setwise(train_index=np.arange(0,250), val_index = np.arange(250, 300), test_index = np.arange(300, 400),\n",
        "                    model_name = \"trained_model_060621_deeplabv3_nocut\", model_trained = None):\n",
        "  if model_trained is None:\n",
        "    load_model(model_name)\n",
        "  avg_confusion_matrix_train, avg_mIOU_vector_train = multiple_images_metrics(img_index = train_index, model_trained = model_trained)\n",
        "  avg_confusion_matrix_val, avg_mIOU_vector_val = multiple_images_metrics(img_index = val_index, model_trained = model_trained)\n",
        "  avg_confusion_matrix_test, avg_mIOU_vector_test = multiple_images_metrics(img_index = test_index, model_trained = model_trained)\n",
        "  print( metrics_from_confusion(avg_confusion_matrix_train, save_name = \"overall_metrics_train\") )\n",
        "  print( metrics_from_confusion(avg_confusion_matrix_val, save_name = \"overall_metrics_val\") )\n",
        "  print( metrics_from_confusion(avg_confusion_matrix_test, save_name = \"overall_metrics_test\") )\n",
        "\n",
        "\n",
        "def generate_overall_metrics_table(save_name = \"overall_metrics_table\", train_pickle_name = \"overall_metrics_train\", val_pickle_name = \"overall_metrics_val\", test_pickle_name = \"overall_metrics_test\", permute_matrix = freq_list_argsort):\n",
        "  recall_train, precision_train, false_negative_rate_train, recall_class_train, precision_class_train, false_negative_rate_class_train = load_metrics_from_confusion(train_pickle_name)\n",
        "  recall_val, precision_val, false_negative_rate_val, recall_class_val, precision_class_val, false_negative_rate_class_val = load_metrics_from_confusion(val_pickle_name)\n",
        "  recall_test, precision_test, false_negative_rate_test, recall_class_test, precision_class_test, false_negative_rate_class_test = load_metrics_from_confusion(test_pickle_name)\n",
        "  \n",
        "  recall_class_train, precision_class_train, false_negative_rate_class_train = recall_class_train[permute_matrix], precision_class_train[permute_matrix], false_negative_rate_class_train[permute_matrix]\n",
        "  recall_class_val, precision_class_val, false_negative_rate_class_val = recall_class_val[permute_matrix], precision_class_val[permute_matrix], false_negative_rate_class_val[permute_matrix]\n",
        "  recall_class_test, precision_class_test, false_negative_rate_class_test = recall_class_test[permute_matrix], precision_class_test[permute_matrix], false_negative_rate_class_test[permute_matrix]\n",
        "  \n",
        "  numpy_table = np.array([\n",
        "                          np.append( recall_class_train, recall_train),\n",
        "                          np.append( precision_class_train, precision_train),\n",
        "                          np.append( false_negative_rate_class_train, false_negative_rate_train),\n",
        "                          np.append( recall_class_val, recall_val),\n",
        "                          np.append( precision_class_val, precision_val ),\n",
        "                          np.append( false_negative_rate_class_val, false_negative_rate_val),\n",
        "                          np.append( recall_class_test, recall_test),\n",
        "                          np.append( precision_class_test, precision_test),\n",
        "                          np.append( false_negative_rate_class_test, false_negative_rate_test)\n",
        "  ]).transpose()\n",
        "  print(numpy_table)\n",
        "  columns_df = np.array([\"Recall (Train)\", \"Precision (Train)\", \"FNR (Train)\", \"Recall (Val)\", \"Precision (Val)\",\n",
        "                       \"FNR (Val)\", \"Recall (Test)\", \"Precision (Test)\", \"FNR (Test)\"])\n",
        "  index_df = np.append( np.array(class_names)[permute_matrix], \"Total\")\n",
        "  ov_metrics_df = pd.DataFrame(numpy_table, index = index_df, columns = columns_df ).round(decimals=3)\n",
        "  ov_metrics_df.to_csv(analise_dir + save_name + '.csv', decimal=',')\n",
        "  print(ov_metrics_df.head())\n",
        "\n",
        "def show_img_from_array(Img):\n",
        "  Img = Img.astype(np.uint8)\n",
        "  fig, ax = plt.subplots(nrows=1, ncols=1)\n",
        "  ax.imshow(Img)\n",
        "\n",
        "def detect_and_save(img_name, model_trained = model_trained):\n",
        "  rsize = (1200, 800)\n",
        "  Img, Gt, Y_pred_rgb, confused_matrix, mIOU = detect_and_analyse(img_name, model_trained, return_images = True)\n",
        "  # Img = Image.fromarray(Img.squeeze())\n",
        "  Gt = Image.fromarray(Gt.squeeze()).resize(rsize, resample=Image.NEAREST)\n",
        "  Y_pred_rgb = Image.fromarray(Y_pred_rgb.squeeze()).resize(rsize, resample=Image.NEAREST)\n",
        "\n",
        "  # Img.save(analise_dir + img_name + '_orig.jpg')\n",
        "  Gt.save(analise_dir + \"detections/\" + img_name + '_gt.png')\n",
        "  Y_pred_rgb.save(analise_dir + \"detections/\" + img_name + '_pred.png')\n",
        "\n",
        "def detect_multiple_and_save(img_index, model_trained = model_trained):\n",
        "  img_path = working_dir + 'images/*.jpg'\n",
        "  img_set = [imname.split('/')[-1].split('.')[0] for imname in glob.glob(img_path)]\n",
        "  img_set = np.array(sorted(img_set, key=lambda x: int(x)))[img_index]\n",
        "  for i, img in enumerate(img_set):\n",
        "    print(img)\n",
        "    detect_and_save(img, model_trained)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjasvR5rzdE-"
      },
      "source": [
        "metrics_setwise(train_index=np.arange(0,250), val_index = np.arange(250, 300), test_index = np.arange(300, 400), model_trained = model_trained)\n",
        "# metrics_setwise(train_index=np.arange(0,10), val_index = np.arange(10,20), test_index = np.arange(20, 30), model_trained = model_trained)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0YiG9bH67G3",
        "outputId": "51ec0051-fa83-477f-9b6e-a9291f7acc17"
      },
      "source": [
        "generate_overall_metrics_table(save_name = \"overall_metrics_table\", train_pickle_name = \"overall_metrics_train\", val_pickle_name = \"overall_metrics_val\", test_pickle_name = \"overall_metrics_test\", permute_matrix = freq_list_argsort)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SemanticDroneDataset/analise/overall_metrics_train.pkl rb\n",
            "/content/SemanticDroneDataset/analise/overall_metrics_val.pkl rb\n",
            "/content/SemanticDroneDataset/analise/overall_metrics_test.pkl rb\n",
            "[[0.84850127 0.18941324 0.15149873 0.79786742 0.15561623 0.20213258\n",
            "  0.77502777 0.13106858 0.22497223]\n",
            " [0.61717329 0.27585719 0.38282671 0.59218421 0.2429521  0.40781579\n",
            "  0.51304511 0.26574149 0.48695489]\n",
            " [0.64699631 0.78473065 0.35300369 0.65737437 0.69067805 0.34262563\n",
            "  0.58970605 0.72095151 0.41029395]\n",
            " [0.52792596 0.42082391 0.47207404 0.37336124 0.27312204 0.62663876\n",
            "  0.41407219 0.24252396 0.58592781]\n",
            " [0.45618141 0.36877096 0.54381859 0.36219387 0.30979873 0.63780613\n",
            "  0.38721231 0.29649279 0.61278769]\n",
            " [0.62581823 0.28835896 0.37418177 0.45071007 0.18679235 0.54928993\n",
            "  0.36349966 0.15223822 0.63650034]\n",
            " [0.36464689 0.44219803 0.63535311 0.27146308 0.27674333 0.72853692\n",
            "  0.24486292 0.30517014 0.75513708]\n",
            " [0.71177422 0.31438925 0.28822578 0.44610881 0.17609243 0.55389119\n",
            "  0.55055214 0.20460222 0.44944786]\n",
            " [0.46250443 0.85976171 0.53749557 0.49522647 0.83126077 0.50477353\n",
            "  0.45533623 0.84780369 0.54466377]\n",
            " [0.43098137 0.85489617 0.56901863 0.34126076 0.82666301 0.65873924\n",
            "  0.32846717 0.76688864 0.67153283]\n",
            " [0.18668996 0.91890752 0.81331004 0.06871255 0.85075811 0.93128745\n",
            "  0.06144276 0.8707714  0.93855724]\n",
            " [0.45881494 0.5912483  0.54118506 0.28442052 0.57703642 0.71557948\n",
            "  0.29171644 0.43638647 0.70828356]\n",
            " [0.33637278 0.70854967 0.66362722 0.26513344 0.49908776 0.73486656\n",
            "  0.13656376 0.60361561 0.86343624]\n",
            " [0.35968436 0.9767653  0.64031564 0.28479923 0.97227615 0.71520077\n",
            "  0.28184431 0.97584397 0.71815569]\n",
            " [0.28568257 0.84432013 0.71431743 0.23855808 0.81521495 0.76144192\n",
            "  0.14935926 0.56517369 0.85064074]\n",
            " [0.38080941 0.85804032 0.61919059 0.09335295 0.66333252 0.90664705\n",
            "  0.14046956 0.72386679 0.85953044]\n",
            " [0.61424773 0.99416033 0.38575227 0.40939522 0.99653695 0.59060478\n",
            "  0.37066554 0.99300828 0.62933446]\n",
            " [0.65236816 0.89525367 0.34763184 0.66638354 0.61276072 0.33361646\n",
            "  0.50102868 0.88156784 0.49897132]\n",
            " [0.80904791 0.93897057 0.19095209 0.61612462 0.87982583 0.38387538\n",
            "  0.7295475  0.85403384 0.2704525 ]\n",
            " [0.26898197 0.89774988 0.73101803 0.09571668 0.70732002 0.90428332\n",
            "  0.02763593 0.69051743 0.97236407]\n",
            " [0.68880851 0.8426375  0.31119149 0.59016393 0.77366226 0.40983607\n",
            "  0.63578371 0.79932391 0.36421629]\n",
            " [0.39421843 0.997121   0.60578157 0.                nan 1.\n",
            "  0.11653386 0.98646823 0.88346614]\n",
            " [0.34028777 0.99742425 0.65971223 0.0836215  0.99810833 0.9163785\n",
            "  0.01663051 0.98965009 0.98336949]\n",
            " [0.65996973 0.3683808  0.34003027 0.59200415 0.3072519  0.40799585\n",
            "  0.56313714 0.30072861 0.43686286]]\n",
            "            Recall (Train)  Precision (Train)  ...  Precision (Test)  FNR (Test)\n",
            "paved-area           0.849              0.189  ...             0.131       0.225\n",
            "grass                0.617              0.276  ...             0.266       0.487\n",
            "roof                 0.647              0.785  ...             0.721       0.410\n",
            "gravel               0.528              0.421  ...             0.243       0.586\n",
            "vegetation           0.456              0.369  ...             0.296       0.613\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ppwC02NAIeK"
      },
      "source": [
        "# Detect and save all test set:\n",
        "detect_multiple_and_save(np.arange(300, 400), model_trained = model_trained)\n",
        "# detect_and_save('582', model_trained = model_trained)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uffgMggMAJW-"
      },
      "source": [
        "### Plot Confusion Matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCRH_1BMLhpp"
      },
      "source": [
        "plot_confusion_matrix(avg_confusion_matrix, figname=\"confusion_matrix_testset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4F31bXOQXHr"
      },
      "source": [
        "plot_confusion_matrix(avg_confusion_matrix_train, figname=\"confusion_matrix_testset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkmLOD9zN98x"
      },
      "source": [
        "print( np.sum(confused_matrix, axis = 1).reshape(-1,1) + 1e-9)\n",
        "print(confused_matrix)\n",
        "print(confused_matrix/np.sum(confused_matrix+1e-9, axis = 1).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZE-kw8UHVzB"
      },
      "source": [
        "Img, Y_pred_rgb, mIOU, confused_matrix = detect_and_analyse(img_name = '000', model_name = \"trained_model_060621_deeplabv3_nocut\")\n",
        "show_img_from_array(Y_pred_rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ajX-GTgAuCI"
      },
      "source": [
        "## History"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sxxadsW8zOa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRjxDdjYAxgm"
      },
      "source": [
        "# Grafico de acuracia do treinamento\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Acurcia')\n",
        "plt.ylabel('Acurcia')\n",
        "plt.xlabel('poca')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P2i4ey4A95y"
      },
      "source": [
        "# Grafico de loss do treinamento\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Funo de custo')\n",
        "plt.ylabel('Custo')\n",
        "plt.xlabel('poca')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}